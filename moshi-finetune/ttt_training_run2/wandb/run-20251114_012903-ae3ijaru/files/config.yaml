_wandb:
    value:
        cli_version: 0.21.0
        e:
            tznipmata3vw4o6ye0nsoeaqjhkv6q2c:
                args:
                    - example/moshi_7B.yaml
                codePath: moshi-finetune/train.py
                codePathLocal: train.py
                cpu_count: 32
                cpu_count_logical: 64
                cudaVersion: "12.7"
                disk:
                    /:
                        total: "861060038656"
                        used: "26257203200"
                email: alufr@post.bgu.ac.il
                executable: /home/alufr/.conda/envs/moshi_ttt_fixed/bin/python3.10
                git:
                    commit: e4bcd407f6876b93427ea567150f90c03202a077
                    remote: https://github.com/AlufRon/moshi_in_place
                gpu: NVIDIA RTX 6000 Ada Generation
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 18176
                      memoryTotal: "51527024640"
                      name: NVIDIA RTX 6000 Ada Generation
                      uuid: GPU-c0a5960d-436e-ed63-c025-03b50566cc9f
                host: cs-6000-01.auth.ad.bgu.ac.il
                memory:
                    total: "540345528320"
                os: Linux-5.14.0-503.29.1.el9_5.x86_64-x86_64-with-glibc2.34
                program: /home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py
                python: CPython 3.10.18
                root: ttt_training_run2
                slurm:
                    cluster_name: cluster
                    conf: /var/spool/slurmd/conf-cache/slurm.conf
                    cpus_on_node: "8"
                    cpus_per_task: "8"
                    gpus: rtx_6000:1
                    gpus_on_node: "1"
                    gtids: "0"
                    job_account: eliyanac
                    job_cpus_per_node: "8"
                    job_end_time: "1763162931"
                    job_gid: "1945600513"
                    job_gpus: "3"
                    job_id: "8158380"
                    job_name: yarn-ttt
                    job_nodelist: cs-6000-01
                    job_num_nodes: "1"
                    job_partition: gpu
                    job_qos: normal
                    job_start_time: "1763076531"
                    job_uid: "343889179"
                    job_user: alufr
                    jobid: "8158380"
                    localid: "0"
                    mem_per_node: "51200"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: cs-6000-01
                    oom_kill_step: "0"
                    prio_process: "0"
                    procid: "0"
                    script_context: prolog_task
                    submit_dir: /home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune
                    submit_host: ise-6000-08.auth.ad.bgu.ac.il
                    task_pid: "3478352"
                    tasks_per_node: "1"
                    topology_addr: cs-6000-01
                    topology_addr_pattern: node
                    tres_per_task: cpu=8
                startedAt: "2025-11-13T23:29:03.591812Z"
                writerId: tznipmata3vw4o6ye0nsoeaqjhkv6q2c
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 49
                - 105
            "2":
                - 1
                - 49
                - 105
            "3":
                - 2
                - 13
                - 16
                - 61
            "4": 3.10.18
            "5": 0.21.0
            "12": 0.21.0
            "13": linux-x86_64
batch_size:
    value: 4
ckpt_freq:
    value: 100
data:
    value:
        eval_data: ""
        shuffle: false
        train_data: /sise/eliyanac-group/ron_al/talkbank_callhome_english/talkbank.jsonl
do_ckpt:
    value: true
do_eval:
    value: false
duration_sec:
    value: 100
eval_freq:
    value: 100
first_codebook_weight_multiplier:
    value: 100
full_finetuning:
    value: false
gradient_checkpointing:
    value: true
log_freq:
    value: 1
lora:
    value:
        enable: false
        ft_embed: false
        rank: 64
        scaling: 2
max_norm:
    value: 1
max_steps:
    value: 2000
moshi_paths:
    value:
        config_path: null
        hf_repo_id: kyutai/moshiko-pytorch-bf16
        mimi_path: null
        moshi_path: null
        tokenizer_path: null
num_ckpt_keep:
    value: 3
num_microbatches:
    value: 1
optim:
    value:
        lr: 4e-06
        pct_start: 0.05
        weight_decay: 0.1
overwrite_run_dir:
    value: true
param_dtype:
    value: bfloat16
run_dir:
    value: ./ttt_training_run2
save_adapters:
    value: true
seed:
    value: 0
text_padding_weight:
    value: 0.5
ttt:
    value:
        chunk_size: 256
        conv_kernel_size: 2
        enabled: true
        layer_frequency: 10
        learning_rate: 0.001
        start_layer: 10
        unfreeze_ttt_layers: false
wandb:
    value:
        key: ""
        offline: false
        project: moshi_in_place1
        run_name: run1
world_size:
    value: 1
yarn:
    value:
        beta_fast: 32
        beta_slow: 1
        enabled: true
        mscale: 1
        mscale_all_dim: 0
        original_max_seq_len: 3000
        scale: 4
