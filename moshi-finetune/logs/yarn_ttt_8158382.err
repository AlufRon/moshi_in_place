[rank0]:[W1114 01:33:01.498127575 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
wandb: Currently logged in as: alufr (alufr-ben-gurion-university-of-the-negev) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_013301-9hndyql6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: üöÄ View run at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/9hndyql6
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/loaders.py:203: UserWarning: Repository kyutai/moshiko-pytorch-bf16 contains no config.json. Assuming this is a Moshi 7B. Support for such repository might be removed in the future.
  warnings.warn(
wandb: uploading summary, console lines 47-47
wandb:                                                                                
wandb: üöÄ View run run2 at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/9hndyql6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_013301-9hndyql6/logs
Traceback (most recent call last):
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 449, in <module>
    fire.Fire(train)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 60, in train
    _train(args, exit_stack)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 280, in _train
    output = model(codes=codes, condition_tensors=condition_tensors)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/lm.py", line 363, in forward
    transformer_out, text_logits = self.forward_text(delayed_codes[:, :, :-1], sum_condition, cross_attention_src)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/lm.py", line 405, in forward_text
    transformer_out = self.transformer(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 946, in forward
    y = torch_checkpoint(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
    return disable_fn(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 496, in checkpoint
    ret = function(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 808, in forward
    x = self._ff_block(x, token_embeddings)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 776, in _ff_block
    update = self.gating(x, token_embeddings)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 134, in forward
    return self._ttt_forward(x, token_embeddings)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 165, in _ttt_forward
    return self._parallel_ttt_update(Z, V_hat)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 273, in _parallel_ttt_update
    W_eff = W_init_bc + self.ttt_lr * S
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 448.00 KiB is free. Including non-PyTorch memory, this process has 47.39 GiB memory in use. Of the allocated memory 46.43 GiB is allocated by PyTorch, and 138.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 449, in <module>
[rank0]:     fire.Fire(train)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
[rank0]:     component, remaining_args = _CallAndUpdateTrace(
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
[rank0]:     component = fn(*varargs, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 60, in train
[rank0]:     _train(args, exit_stack)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 280, in _train
[rank0]:     output = model(codes=codes, condition_tensors=condition_tensors)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/lm.py", line 363, in forward
[rank0]:     transformer_out, text_logits = self.forward_text(delayed_codes[:, :, :-1], sum_condition, cross_attention_src)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/lm.py", line 405, in forward_text
[rank0]:     transformer_out = self.transformer(
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 946, in forward
[rank0]:     y = torch_checkpoint(
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/_compile.py", line 32, in inner
[rank0]:     return disable_fn(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 496, in checkpoint
[rank0]:     ret = function(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 808, in forward
[rank0]:     x = self._ff_block(x, token_embeddings)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/transformer.py", line 776, in _ff_block
[rank0]:     update = self.gating(x, token_embeddings)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 134, in forward
[rank0]:     return self._ttt_forward(x, token_embeddings)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 165, in _ttt_forward
[rank0]:     return self._parallel_ttt_update(Z, V_hat)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/modules/ttt_module.py", line 273, in _parallel_ttt_update
[rank0]:     W_eff = W_init_bc + self.ttt_lr * S
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.88 GiB. GPU 0 has a total capacity of 47.40 GiB of which 448.00 KiB is free. Including non-PyTorch memory, this process has 47.39 GiB memory in use. Of the allocated memory 46.43 GiB is allocated by PyTorch, and 138.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1114 01:33:21.889791095 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
E1114 01:33:23.360000 3490939 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 3490951) of binary: /home/alufr/.conda/envs/moshi_ttt_fixed/bin/python3.10
Traceback (most recent call last):
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-14_01:33:23
  host      : cs-6000-01.auth.ad.bgu.ac.il
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3490951)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
