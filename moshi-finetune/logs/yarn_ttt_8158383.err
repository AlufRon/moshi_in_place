[rank0]:[W1114 01:34:02.377875255 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
wandb: Currently logged in as: alufr (alufr-ben-gurion-university-of-the-negev) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_013402-gra8h0t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run2
wandb: â­ï¸ View project at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: ğŸš€ View run at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/gra8h0t1
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/loaders.py:203: UserWarning: Repository kyutai/moshiko-pytorch-bf16 contains no config.json. Assuming this is a Moshi 7B. Support for such repository might be removed in the future.
  warnings.warn(
wandb: uploading output.log; uploading config.yaml
wandb: uploading history steps 1999-1999, summary, console lines 4142-4147
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           train/allocated_mem â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/avg_wps â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          train/eta_in_seconds â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–
wandb:                    train/loss â–‚â–†â–‚â–‡â–â–„â–„â–‚â–‚â–ˆâ–„â–ƒâ–‚â–„â–„â–‚â–…â–ƒâ–„â–„â–†â–‡â–‡â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–„â–â–‚â–â–‚â–„â–‚â–‡
wandb:                      train/lr â–‚â–‚â–„â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–
wandb:      train/peak_allocated_mem â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            train/percent_done â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        train/prob_real_tokens â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          train/ttt/delta_norm â–ˆâ–ˆâ–ˆâ–‡â–…â–…â–†â–„â–…â–†â–…â–†â–„â–„â–†â–„â–„â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:           train/ttt/grad_norm â–â–‚â–‡â–„â–„â–„â–„â–‡â–…â–‚â–…â–ˆâ–…â–„â–ˆâ–„â–…â–„â–…â–…â–ƒâ–„â–„â–„â–ˆâ–ˆâ–†â–†â–„â–…â–„â–„â–„â–…â–‡â–„â–„â–…â–…â–ƒ
wandb:         train/ttt/param_count â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/ttt/param_norm â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: train/ttt/relative_change_pct â–â–â–ƒâ–ˆâ–†â–…â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                     train/wps â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:           train/allocated_mem 18.6341
wandb:                 train/avg_wps 5274.43053
wandb:          train/eta_in_seconds 0
wandb:                    train/loss 3.69605
wandb:                      train/lr 0.0
wandb:      train/peak_allocated_mem 34.45884
wandb:            train/percent_done 100
wandb:        train/prob_real_tokens 0.9915
wandb:          train/ttt/delta_norm 0.0
wandb:           train/ttt/grad_norm 0.79952
wandb:         train/ttt/param_count 6
wandb:          train/ttt/param_norm 18.11408
wandb: train/ttt/relative_change_pct 0.0
wandb:                     train/wps 5295.98837
wandb: 
wandb: ğŸš€ View run run2 at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/gra8h0t1
wandb: â­ï¸ View project at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_013402-gra8h0t1/logs
[rank0]:[W1114 05:08:46.978379169 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
