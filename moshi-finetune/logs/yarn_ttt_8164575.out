==================================================
Job started at: Fri 14 Nov 2025 16:55:14 IST
Running on node: ise-6000-01.auth.ad.bgu.ac.il
GPU info:
Fri Nov 14 16:55:14 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:E1:00.0 Off |                  Off |
| 30%   26C    P8             25W /  300W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
==================================================
Set CUDA_VISIBLE_DEVICES=0
Starting YARN + TTT training...
Context Extension: 4x (3000 -> 12000 tokens)
TTT Layers: 3 (layers 10, 20, 30)
Base Model: Frozen (only TTT params trained)
Warning: `hf_repo_id` is set but `config_path` is None. This will load default models.
2025-11-14 16:55:22 (IST) - 0:00:04 - distributed - INFO - torch.cuda.device_count: 1
2025-11-14 16:55:22 (IST) - 0:00:04 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0
2025-11-14 16:55:22 (IST) - 0:00:04 - distributed - INFO - local rank: 0
2025-11-14 16:55:22 (IST) - 0:00:04 - train - INFO - Going to init comms...
2025-11-14 16:55:22 (IST) - 0:00:04 - train - INFO - Run dir: /sise/eliyanac-group/ron_al/ttt_training_run2
2025-11-14 16:55:22 (IST) - 0:00:04 - train - INFO - Removing run dir /sise/eliyanac-group/ron_al/ttt_training_run2...
2025-11-14 16:55:22 (IST) - 0:00:05 - train - INFO - TrainArgs: {'batch_size': 2,
 'ckpt_freq': 100,
 'data': {'eval_data': '',
          'shuffle': False,
          'train_data': '/sise/eliyanac-group/ron_al/talkbank_callhome_english/talkbank.jsonl'},
 'do_ckpt': True,
 'do_eval': False,
 'duration_sec': 150.0,
 'eval_freq': 100,
 'first_codebook_weight_multiplier': 100.0,
 'full_finetuning': False,
 'gradient_checkpointing': True,
 'log_freq': 1,
 'lora': {'enable': False, 'ft_embed': False, 'rank': 64, 'scaling': 2.0},
 'max_norm': 1.0,
 'max_steps': 2000,
 'moshi_paths': {'config_path': None,
                 'hf_repo_id': 'kyutai/moshiko-pytorch-bf16',
                 'mimi_path': None,
                 'moshi_path': None,
                 'tokenizer_path': None},
 'num_ckpt_keep': 3,
 'num_microbatches': 1,
 'optim': {'lr': 0.01, 'pct_start': 0.05, 'weight_decay': 0.1},
 'overwrite_run_dir': True,
 'param_dtype': 'bfloat16',
 'run_dir': '/sise/eliyanac-group/ron_al/ttt_training_run2',
 'save_adapters': True,
 'seed': 0,
 'text_padding_weight': 0.5,
 'ttt': {'chunk_size': 256,
         'conv_kernel_size': 2,
         'delta_clip_fro_norm': 100.0,
         'enabled': True,
         'layer_frequency': 10,
         'learning_rate': 0.0001,
         'start_layer': 10,
         'unfreeze_ttt_layers': False},
 'wandb': {'key': '',
           'offline': False,
           'project': 'moshi_in_place',
           'run_name': 'run2'},
 'world_size': 1,
 'yarn': {'beta_fast': 32,
          'beta_slow': 1,
          'enabled': True,
          'mscale': 1.0,
          'mscale_all_dim': 0.0,
          'original_max_seq_len': 3000,
          'scale': 4.0}}
2025-11-14 16:55:22 (IST) - 0:00:05 - metrics_logger - INFO - initializing wandb
2025-11-14 16:55:24 (IST) - 0:00:07 - train - INFO - Loading Mimi and Moshi...
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - TTT (Test-Time Training) ENABLED
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Layer frequency: 10
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Start layer: 10
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Chunk size: 256
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Learning rate: 0.0001
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Conv kernel: 2
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - YaRN (Context Window Extension) ENABLED
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Scale: 4.0x
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Original max seq len: 3000
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Beta fast: 32
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   Beta slow: 1
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - ======================================================================
[YaRN] Enabled with scale=4.0, original_len=3000
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[YaRN] Initializing RoPE buffers on device=meta
[YaRN] RoPE buffers initialized successfully
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - Initializing TTT w_down from pretrained checkpoint...
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ transformer.layers.10.gating.w_down <- transformer.layers.10.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ transformer.layers.20.gating.w_down <- transformer.layers.20.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ transformer.layers.30.gating.w_down <- transformer.layers.30.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:55:26 (IST) - 0:00:08 - finetune.wrapped_model - INFO - Initializing TTT layers ...
2025-11-14 16:55:27 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.10.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:27 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.10.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:27 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.10.gating.w_down_pretrained from w_down
2025-11-14 16:55:27 (IST) - 0:00:09 - finetune.wrapped_model - WARNING - Buffer transformer.layers.10.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:55:28 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.20.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:28 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.20.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:28 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.20.gating.w_down_pretrained from w_down
2025-11-14 16:55:28 (IST) - 0:00:10 - finetune.wrapped_model - WARNING - Buffer transformer.layers.20.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.30.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.30.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.30.gating.w_down_pretrained from w_down
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - WARNING - Buffer transformer.layers.30.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - INFO - Initializing YaRN RoPE buffers ...
2025-11-14 16:55:29 (IST) - 0:00:11 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.rope.inv_freq (shape: torch.Size([64]), scale: 4.0x)
2025-11-14 16:55:29 (IST) - 0:00:12 - finetune.wrapped_model - INFO - Finished initialization!
2025-11-14 16:55:29 (IST) - 0:00:12 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:29 (IST) - 0:00:12 - finetune.wrapped_model - INFO - TTT ACTIVE: 3 layers enabled
2025-11-14 16:55:29 (IST) - 0:00:12 - finetune.wrapped_model - INFO - TTT layer indices: [10, 20, 30]
2025-11-14 16:55:29 (IST) - 0:00:12 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:55:39 (IST) - 0:00:21 - train - INFO - [DocStream] step=1 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=0-1]
2025-11-14 16:55:39 (IST) - 0:00:21 - train - INFO - [TTT RESET] Document switch detected: None -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/0638.wav
2025-11-14 16:55:39 (IST) - 0:00:21 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.980469; w_down is frozen during training so its norm stays constant
2025-11-14 16:55:39 (IST) - 0:00:21 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.982422; w_down is frozen during training so its norm stays constant
2025-11-14 16:55:39 (IST) - 0:00:21 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.980469; w_down is frozen during training so its norm stays constant
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000001
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   requires_grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   has grad: True
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO -   grad norm: 0.000001
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - =========================

2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - [TTT] Step 1: grad_norm=1.433e-06, param_norm=1.2227, delta_norm=5.450e-02, relative_change=4.4577% (6 params)
2025-11-14 16:55:52 (IST) - 0:00:34 - train - INFO - step: 000001 - done (%): 0.1 - loss: 3.378 - lr: 4.0e-04 - peak_alloc_mem (GB): 35.5 - alloc_mem (GB): 18.6 - words_per_second: 1647.6 - avg_words_per_second: 1647.6 - ETA: >2025-11-15 04:18:21
2025-11-14 16:55:52 (IST) - 0:00:35 - train - INFO - [DocStream] step=2 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=2-3]
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   requires_grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   has grad: True
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO -   grad norm: 0.000000
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - =========================

2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - [TTT] Step 2: grad_norm=3.786e-07, param_norm=1.2242, delta_norm=2.827e-02, relative_change=2.3090% (6 params)
2025-11-14 16:55:58 (IST) - 0:00:40 - train - INFO - step: 000002 - done (%): 0.1 - loss: 3.943 - lr: 4.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5604.5 - avg_words_per_second: 2546.5 - ETA: >2025-11-15 00:17:18
2025-11-14 16:55:59 (IST) - 0:00:42 - train - INFO - [DocStream] step=3 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=4-5]
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   requires_grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   has grad: True
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - =========================

2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - [TTT] Step 3: grad_norm=1.549e-07, param_norm=1.2255, delta_norm=1.911e-02, relative_change=1.5591% (6 params)
2025-11-14 16:56:05 (IST) - 0:00:47 - train - INFO - step: 000003 - done (%): 0.1 - loss: 3.365 - lr: 4.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 4820.1 - avg_words_per_second: 3021.6 - ETA: >2025-11-14 23:07:50
2025-11-14 16:56:05 (IST) - 0:00:48 - train - INFO - [DocStream] step=4 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=0-1]
2025-11-14 16:56:05 (IST) - 0:00:48 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/0638.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4065.wav
2025-11-14 16:56:05 (IST) - 0:00:48 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.982422; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:05 (IST) - 0:00:48 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.986328; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:05 (IST) - 0:00:48 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   requires_grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   has grad: True
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO -   grad norm: 0.000000
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - =========================

2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - [TTT] Step 4: grad_norm=1.882e-07, param_norm=1.2267, delta_norm=1.453e-02, relative_change=1.1844% (6 params)
2025-11-14 16:56:11 (IST) - 0:00:53 - train - INFO - step: 000004 - done (%): 0.2 - loss: 4.810 - lr: 4.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5546.2 - avg_words_per_second: 3409.6 - ETA: >2025-11-14 22:25:28
2025-11-14 16:56:11 (IST) - 0:00:54 - train - INFO - [DocStream] step=5 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=2-3]
2025-11-14 16:56:17 (IST) - 0:01:00 - train - INFO - [TTT] Step 5: grad_norm=2.074e-07, param_norm=1.2278, delta_norm=1.201e-02, relative_change=0.9781% (6 params)
2025-11-14 16:56:17 (IST) - 0:01:00 - train - INFO - step: 000005 - done (%): 0.2 - loss: 4.949 - lr: 4.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5457.2 - avg_words_per_second: 3686.3 - ETA: >2025-11-14 22:00:43
2025-11-14 16:56:18 (IST) - 0:01:00 - train - INFO - [DocStream] step=6 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=4-5]
2025-11-14 16:56:23 (IST) - 0:01:06 - train - INFO - [TTT] Step 6: grad_norm=1.831e-07, param_norm=1.2288, delta_norm=1.037e-02, relative_change=0.8443% (6 params)
2025-11-14 16:56:23 (IST) - 0:01:06 - train - INFO - step: 000006 - done (%): 0.3 - loss: 3.374 - lr: 4.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5526.4 - avg_words_per_second: 3902.8 - ETA: >2025-11-14 21:43:46
2025-11-14 16:56:24 (IST) - 0:01:06 - train - INFO - [DocStream] step=7 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=6-7]
2025-11-14 16:56:29 (IST) - 0:01:12 - train - INFO - [TTT] Step 7: grad_norm=1.018e-07, param_norm=1.2297, delta_norm=9.214e-03, relative_change=0.7493% (6 params)
2025-11-14 16:56:29 (IST) - 0:01:12 - train - INFO - step: 000007 - done (%): 0.3 - loss: 2.610 - lr: 4.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5507.3 - avg_words_per_second: 4072.3 - ETA: >2025-11-14 21:31:47
2025-11-14 16:56:30 (IST) - 0:01:12 - train - INFO - [DocStream] step=8 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=8-9]
2025-11-14 16:56:36 (IST) - 0:01:18 - train - INFO - [TTT] Step 8: grad_norm=7.861e-08, param_norm=1.2306, delta_norm=8.389e-03, relative_change=0.6817% (6 params)
2025-11-14 16:56:36 (IST) - 0:01:18 - train - INFO - step: 000008 - done (%): 0.4 - loss: 2.319 - lr: 5.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5497.8 - avg_words_per_second: 4208.7 - ETA: >2025-11-14 21:22:49
2025-11-14 16:56:36 (IST) - 0:01:18 - train - INFO - [DocStream] step=9 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=10-11]
2025-11-14 16:56:42 (IST) - 0:01:24 - train - INFO - [TTT] Step 9: grad_norm=8.817e-08, param_norm=1.2315, delta_norm=7.786e-03, relative_change=0.6323% (6 params)
2025-11-14 16:56:42 (IST) - 0:01:24 - train - INFO - step: 000009 - done (%): 0.5 - loss: 2.321 - lr: 5.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5482.0 - avg_words_per_second: 4320.2 - ETA: >2025-11-14 21:15:56
2025-11-14 16:56:42 (IST) - 0:01:25 - train - INFO - [DocStream] step=10 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=0-1]
2025-11-14 16:56:42 (IST) - 0:01:25 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4065.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4074.wav
2025-11-14 16:56:42 (IST) - 0:01:25 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.986328; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:42 (IST) - 0:01:25 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:42 (IST) - 0:01:25 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.001953; w_down is frozen during training so its norm stays constant
2025-11-14 16:56:48 (IST) - 0:01:30 - train - INFO - [TTT] Step 10: grad_norm=1.158e-07, param_norm=1.2323, delta_norm=7.379e-03, relative_change=0.5988% (6 params)
2025-11-14 16:56:48 (IST) - 0:01:30 - train - INFO - step: 000010 - done (%): 0.5 - loss: 5.038 - lr: 5.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5451.2 - avg_words_per_second: 4411.8 - ETA: >2025-11-14 21:10:31
2025-11-14 16:56:48 (IST) - 0:01:31 - train - INFO - [DocStream] step=11 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=2-3]
2025-11-14 16:56:54 (IST) - 0:01:37 - train - INFO - [TTT] Step 11: grad_norm=9.977e-08, param_norm=1.2331, delta_norm=7.104e-03, relative_change=0.5761% (6 params)
2025-11-14 16:56:54 (IST) - 0:01:37 - train - INFO - step: 000011 - done (%): 0.6 - loss: 4.583 - lr: 6.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5456.1 - avg_words_per_second: 4489.9 - ETA: >2025-11-14 21:06:05
2025-11-14 16:56:54 (IST) - 0:01:37 - train - INFO - [DocStream] step=12 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=4-5]
2025-11-14 16:57:00 (IST) - 0:01:43 - train - INFO - [TTT] Step 12: grad_norm=7.572e-08, param_norm=1.2339, delta_norm=6.897e-03, relative_change=0.5590% (6 params)
2025-11-14 16:57:00 (IST) - 0:01:43 - train - INFO - step: 000012 - done (%): 0.6 - loss: 2.718 - lr: 6.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5466.6 - avg_words_per_second: 4557.7 - ETA: >2025-11-14 21:02:21
2025-11-14 16:57:01 (IST) - 0:01:43 - train - INFO - [DocStream] step=13 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=6-7]
2025-11-14 16:57:06 (IST) - 0:01:49 - train - INFO - [TTT] Step 13: grad_norm=1.438e-07, param_norm=1.2347, delta_norm=6.901e-03, relative_change=0.5589% (6 params)
2025-11-14 16:57:06 (IST) - 0:01:49 - train - INFO - step: 000013 - done (%): 0.7 - loss: 3.064 - lr: 7.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5449.2 - avg_words_per_second: 4615.8 - ETA: >2025-11-14 20:59:15
2025-11-14 16:57:07 (IST) - 0:01:49 - train - INFO - [DocStream] step=14 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=8-9]
2025-11-14 16:57:13 (IST) - 0:01:55 - train - INFO - [TTT] Step 14: grad_norm=1.457e-07, param_norm=1.2355, delta_norm=7.094e-03, relative_change=0.5741% (6 params)
2025-11-14 16:57:13 (IST) - 0:01:55 - train - INFO - step: 000014 - done (%): 0.7 - loss: 2.885 - lr: 8.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5438.6 - avg_words_per_second: 4666.3 - ETA: >2025-11-14 20:56:37
2025-11-14 16:57:13 (IST) - 0:01:55 - train - INFO - [DocStream] step=15 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=10-11]
2025-11-14 16:57:19 (IST) - 0:02:01 - train - INFO - [TTT] Step 15: grad_norm=6.662e-08, param_norm=1.2363, delta_norm=7.101e-03, relative_change=0.5743% (6 params)
2025-11-14 16:57:19 (IST) - 0:02:01 - train - INFO - step: 000015 - done (%): 0.8 - loss: 2.802 - lr: 8.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5416.9 - avg_words_per_second: 4709.8 - ETA: >2025-11-14 20:54:23
2025-11-14 16:57:19 (IST) - 0:02:02 - train - INFO - [DocStream] step=16 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=0-1]
2025-11-14 16:57:19 (IST) - 0:02:02 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4074.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4077.wav
2025-11-14 16:57:19 (IST) - 0:02:02 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 16:57:19 (IST) - 0:02:02 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 16:57:19 (IST) - 0:02:02 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.011719; w_down is frozen during training so its norm stays constant
2025-11-14 16:57:25 (IST) - 0:02:08 - train - INFO - [TTT] Step 16: grad_norm=4.632e-07, param_norm=1.2372, delta_norm=6.644e-03, relative_change=0.5371% (6 params)
2025-11-14 16:57:25 (IST) - 0:02:08 - train - INFO - step: 000016 - done (%): 0.8 - loss: 4.238 - lr: 9.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5412.5 - avg_words_per_second: 4748.3 - ETA: >2025-11-14 20:52:27
2025-11-14 16:57:25 (IST) - 0:02:08 - train - INFO - [DocStream] step=17 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=2-3]
2025-11-14 16:57:31 (IST) - 0:02:14 - train - INFO - [TTT] Step 17: grad_norm=4.540e-07, param_norm=1.2380, delta_norm=8.350e-03, relative_change=0.6745% (6 params)
2025-11-14 16:57:31 (IST) - 0:02:14 - train - INFO - step: 000017 - done (%): 0.8 - loss: 4.052 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5409.4 - avg_words_per_second: 4782.7 - ETA: >2025-11-14 20:50:45
2025-11-14 16:57:32 (IST) - 0:02:14 - train - INFO - [DocStream] step=18 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=4-5]
2025-11-14 16:57:38 (IST) - 0:02:20 - train - INFO - [TTT] Step 18: grad_norm=6.742e-08, param_norm=1.2388, delta_norm=8.150e-03, relative_change=0.6579% (6 params)
2025-11-14 16:57:38 (IST) - 0:02:20 - train - INFO - step: 000018 - done (%): 0.9 - loss: 2.535 - lr: 1.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5416.4 - avg_words_per_second: 4814.0 - ETA: >2025-11-14 20:49:13
2025-11-14 16:57:38 (IST) - 0:02:21 - train - INFO - [DocStream] step=19 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=6-7]
2025-11-14 16:57:44 (IST) - 0:02:27 - train - INFO - [TTT] Step 19: grad_norm=1.007e-07, param_norm=1.2397, delta_norm=7.928e-03, relative_change=0.6395% (6 params)
2025-11-14 16:57:44 (IST) - 0:02:27 - train - INFO - step: 000019 - done (%): 0.9 - loss: 3.870 - lr: 1.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5257.3 - avg_words_per_second: 4835.4 - ETA: >2025-11-14 20:48:11
2025-11-14 16:57:44 (IST) - 0:02:27 - train - INFO - [DocStream] step=20 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=8-9]
2025-11-14 16:57:50 (IST) - 0:02:33 - train - INFO - [TTT] Step 20: grad_norm=7.653e-08, param_norm=1.2405, delta_norm=7.830e-03, relative_change=0.6312% (6 params)
2025-11-14 16:57:50 (IST) - 0:02:33 - train - INFO - step: 000020 - done (%): 1.0 - loss: 3.452 - lr: 1.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5394.4 - avg_words_per_second: 4860.6 - ETA: >2025-11-14 20:46:59
2025-11-14 16:57:51 (IST) - 0:02:33 - train - INFO - [DocStream] step=21 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=10-11]
2025-11-14 16:57:57 (IST) - 0:02:39 - train - INFO - [TTT] Step 21: grad_norm=4.322e-08, param_norm=1.2414, delta_norm=7.716e-03, relative_change=0.6215% (6 params)
2025-11-14 16:57:57 (IST) - 0:02:39 - train - INFO - step: 000021 - done (%): 1.1 - loss: 1.979 - lr: 1.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5393.0 - avg_words_per_second: 4883.6 - ETA: >2025-11-14 20:45:53
2025-11-14 16:57:57 (IST) - 0:02:39 - train - INFO - [DocStream] step=22 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=0-1]
2025-11-14 16:57:57 (IST) - 0:02:39 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4077.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4092.wav
2025-11-14 16:57:57 (IST) - 0:02:39 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 16:57:57 (IST) - 0:02:39 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.992188; w_down is frozen during training so its norm stays constant
2025-11-14 16:57:57 (IST) - 0:02:39 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.021484; w_down is frozen during training so its norm stays constant
2025-11-14 16:58:03 (IST) - 0:02:45 - train - INFO - [TTT] Step 22: grad_norm=1.188e-07, param_norm=1.2423, delta_norm=7.685e-03, relative_change=0.6186% (6 params)
2025-11-14 16:58:03 (IST) - 0:02:45 - train - INFO - step: 000022 - done (%): 1.1 - loss: 3.864 - lr: 1.4e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5389.9 - avg_words_per_second: 4904.5 - ETA: >2025-11-14 20:44:54
2025-11-14 16:58:03 (IST) - 0:02:46 - train - INFO - [DocStream] step=23 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=2-3]
2025-11-14 16:58:09 (IST) - 0:02:52 - train - INFO - [TTT] Step 23: grad_norm=8.724e-08, param_norm=1.2432, delta_norm=7.606e-03, relative_change=0.6118% (6 params)
2025-11-14 16:58:09 (IST) - 0:02:52 - train - INFO - step: 000023 - done (%): 1.1 - loss: 3.770 - lr: 1.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5395.5 - avg_words_per_second: 4924.0 - ETA: >2025-11-14 20:44:00
2025-11-14 16:58:09 (IST) - 0:02:52 - train - INFO - [DocStream] step=24 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=4-5]
2025-11-14 16:58:15 (IST) - 0:02:58 - train - INFO - [TTT] Step 24: grad_norm=4.224e-08, param_norm=1.2441, delta_norm=7.458e-03, relative_change=0.5994% (6 params)
2025-11-14 16:58:15 (IST) - 0:02:58 - train - INFO - step: 000024 - done (%): 1.2 - loss: 2.563 - lr: 1.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5396.9 - avg_words_per_second: 4942.0 - ETA: >2025-11-14 20:43:10
2025-11-14 16:58:16 (IST) - 0:02:58 - train - INFO - [DocStream] step=25 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=6-7]
2025-11-14 16:58:22 (IST) - 0:03:04 - train - INFO - [TTT] Step 25: grad_norm=3.822e-08, param_norm=1.2450, delta_norm=7.301e-03, relative_change=0.5864% (6 params)
2025-11-14 16:58:22 (IST) - 0:03:04 - train - INFO - step: 000025 - done (%): 1.2 - loss: 2.588 - lr: 1.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5398.2 - avg_words_per_second: 4958.8 - ETA: >2025-11-14 20:42:24
2025-11-14 16:58:22 (IST) - 0:03:04 - train - INFO - [DocStream] step=26 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=8-9]
2025-11-14 16:58:28 (IST) - 0:03:10 - train - INFO - [TTT] Step 26: grad_norm=3.470e-08, param_norm=1.2459, delta_norm=7.162e-03, relative_change=0.5748% (6 params)
2025-11-14 16:58:28 (IST) - 0:03:10 - train - INFO - step: 000026 - done (%): 1.3 - loss: 1.815 - lr: 1.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5389.6 - avg_words_per_second: 4974.1 - ETA: >2025-11-14 20:41:42
2025-11-14 16:58:28 (IST) - 0:03:11 - train - INFO - [DocStream] step=27 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=10-11]
2025-11-14 16:58:34 (IST) - 0:03:17 - train - INFO - [TTT] Step 27: grad_norm=3.301e-08, param_norm=1.2468, delta_norm=7.006e-03, relative_change=0.5619% (6 params)
2025-11-14 16:58:34 (IST) - 0:03:17 - train - INFO - step: 000027 - done (%): 1.4 - loss: 2.477 - lr: 1.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5394.6 - avg_words_per_second: 4988.5 - ETA: >2025-11-14 20:41:03
2025-11-14 16:58:34 (IST) - 0:03:17 - train - INFO - [DocStream] step=28 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=0-1]
2025-11-14 16:58:34 (IST) - 0:03:17 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4092.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4104.wav
2025-11-14 16:58:34 (IST) - 0:03:17 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 16:58:34 (IST) - 0:03:17 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.994141; w_down is frozen during training so its norm stays constant
2025-11-14 16:58:34 (IST) - 0:03:17 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.033203; w_down is frozen during training so its norm stays constant
2025-11-14 16:58:40 (IST) - 0:03:23 - train - INFO - [TTT] Step 28: grad_norm=5.503e-08, param_norm=1.2477, delta_norm=6.822e-03, relative_change=0.5468% (6 params)
2025-11-14 16:58:40 (IST) - 0:03:23 - train - INFO - step: 000028 - done (%): 1.4 - loss: 3.958 - lr: 2.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.8 - avg_words_per_second: 5001.6 - ETA: >2025-11-14 20:40:27
2025-11-14 16:58:41 (IST) - 0:03:23 - train - INFO - [DocStream] step=29 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=2-3]
2025-11-14 16:58:47 (IST) - 0:03:29 - train - INFO - [TTT] Step 29: grad_norm=4.597e-08, param_norm=1.2485, delta_norm=6.693e-03, relative_change=0.5361% (6 params)
2025-11-14 16:58:47 (IST) - 0:03:29 - train - INFO - step: 000029 - done (%): 1.4 - loss: 3.995 - lr: 2.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5389.2 - avg_words_per_second: 5014.0 - ETA: >2025-11-14 20:39:54
2025-11-14 16:58:47 (IST) - 0:03:29 - train - INFO - [DocStream] step=30 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=4-5]
2025-11-14 16:58:53 (IST) - 0:03:35 - train - INFO - [TTT] Step 30: grad_norm=2.587e-08, param_norm=1.2494, delta_norm=6.535e-03, relative_change=0.5231% (6 params)
2025-11-14 16:58:53 (IST) - 0:03:35 - train - INFO - step: 000030 - done (%): 1.5 - loss: 1.973 - lr: 2.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5384.1 - avg_words_per_second: 5025.6 - ETA: >2025-11-14 20:39:23
2025-11-14 16:58:53 (IST) - 0:03:36 - train - INFO - [DocStream] step=31 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=6-7]
2025-11-14 16:58:59 (IST) - 0:03:42 - train - INFO - [TTT] Step 31: grad_norm=2.521e-08, param_norm=1.2502, delta_norm=6.372e-03, relative_change=0.5097% (6 params)
2025-11-14 16:58:59 (IST) - 0:03:42 - train - INFO - step: 000031 - done (%): 1.6 - loss: 2.289 - lr: 2.4e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5377.3 - avg_words_per_second: 5036.2 - ETA: >2025-11-14 20:38:54
2025-11-14 16:59:00 (IST) - 0:03:42 - train - INFO - [DocStream] step=32 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=8-9]
2025-11-14 16:59:05 (IST) - 0:03:48 - train - INFO - [TTT] Step 32: grad_norm=2.822e-08, param_norm=1.2510, delta_norm=6.261e-03, relative_change=0.5005% (6 params)
2025-11-14 16:59:05 (IST) - 0:03:48 - train - INFO - step: 000032 - done (%): 1.6 - loss: 2.075 - lr: 2.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5384.1 - avg_words_per_second: 5046.4 - ETA: >2025-11-14 20:38:27
2025-11-14 16:59:06 (IST) - 0:03:48 - train - INFO - [DocStream] step=33 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=10-11]
2025-11-14 16:59:12 (IST) - 0:03:54 - train - INFO - [TTT] Step 33: grad_norm=2.047e-08, param_norm=1.2517, delta_norm=6.137e-03, relative_change=0.4903% (6 params)
2025-11-14 16:59:12 (IST) - 0:03:54 - train - INFO - step: 000033 - done (%): 1.6 - loss: 1.945 - lr: 2.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5375.9 - avg_words_per_second: 5055.8 - ETA: >2025-11-14 20:38:03
2025-11-14 16:59:12 (IST) - 0:03:55 - train - INFO - [DocStream] step=34 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=0-1]
2025-11-14 16:59:12 (IST) - 0:03:55 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4104.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4112.wav
2025-11-14 16:59:12 (IST) - 0:03:55 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:12 (IST) - 0:03:55 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.996094; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:12 (IST) - 0:03:55 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.041016; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:18 (IST) - 0:04:00 - train - INFO - [TTT] Step 34: grad_norm=5.663e-08, param_norm=1.2525, delta_norm=5.876e-03, relative_change=0.4691% (6 params)
2025-11-14 16:59:18 (IST) - 0:04:01 - train - INFO - step: 000034 - done (%): 1.7 - loss: 4.183 - lr: 2.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5376.1 - avg_words_per_second: 5064.6 - ETA: >2025-11-14 20:37:39
2025-11-14 16:59:18 (IST) - 0:04:01 - train - INFO - [DocStream] step=35 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=2-3]
2025-11-14 16:59:24 (IST) - 0:04:07 - train - INFO - [TTT] Step 35: grad_norm=2.240e-08, param_norm=1.2532, delta_norm=5.624e-03, relative_change=0.4488% (6 params)
2025-11-14 16:59:24 (IST) - 0:04:07 - train - INFO - step: 000035 - done (%): 1.8 - loss: 3.400 - lr: 2.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.1 - avg_words_per_second: 5072.9 - ETA: >2025-11-14 20:37:18
2025-11-14 16:59:25 (IST) - 0:04:07 - train - INFO - [DocStream] step=36 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=4-5]
2025-11-14 16:59:31 (IST) - 0:04:13 - train - INFO - [TTT] Step 36: grad_norm=3.304e-08, param_norm=1.2538, delta_norm=5.448e-03, relative_change=0.4345% (6 params)
2025-11-14 16:59:31 (IST) - 0:04:13 - train - INFO - step: 000036 - done (%): 1.8 - loss: 2.910 - lr: 3.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5364.9 - avg_words_per_second: 5080.6 - ETA: >2025-11-14 20:36:57
2025-11-14 16:59:31 (IST) - 0:04:13 - train - INFO - [DocStream] step=37 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=6-7]
2025-11-14 16:59:37 (IST) - 0:04:19 - train - INFO - [TTT] Step 37: grad_norm=2.708e-08, param_norm=1.2544, delta_norm=5.345e-03, relative_change=0.4261% (6 params)
2025-11-14 16:59:37 (IST) - 0:04:19 - train - INFO - step: 000037 - done (%): 1.9 - loss: 2.659 - lr: 3.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5378.5 - avg_words_per_second: 5088.2 - ETA: >2025-11-14 20:36:38
2025-11-14 16:59:37 (IST) - 0:04:20 - train - INFO - [DocStream] step=38 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=8-9]
2025-11-14 16:59:43 (IST) - 0:04:26 - train - INFO - [TTT] Step 38: grad_norm=2.072e-08, param_norm=1.2550, delta_norm=5.249e-03, relative_change=0.4182% (6 params)
2025-11-14 16:59:43 (IST) - 0:04:26 - train - INFO - step: 000038 - done (%): 1.9 - loss: 2.411 - lr: 3.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5371.7 - avg_words_per_second: 5095.3 - ETA: >2025-11-14 20:36:19
2025-11-14 16:59:44 (IST) - 0:04:26 - train - INFO - [DocStream] step=39 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=10-11]
2025-11-14 16:59:49 (IST) - 0:04:32 - train - INFO - [TTT] Step 39: grad_norm=1.932e-08, param_norm=1.2555, delta_norm=5.194e-03, relative_change=0.4137% (6 params)
2025-11-14 16:59:49 (IST) - 0:04:32 - train - INFO - step: 000039 - done (%): 1.9 - loss: 2.046 - lr: 3.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5372.4 - avg_words_per_second: 5102.0 - ETA: >2025-11-14 20:36:02
2025-11-14 16:59:50 (IST) - 0:04:32 - train - INFO - [DocStream] step=40 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=0-1]
2025-11-14 16:59:50 (IST) - 0:04:32 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4112.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4145.wav
2025-11-14 16:59:50 (IST) - 0:04:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:50 (IST) - 0:04:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.998047; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:50 (IST) - 0:04:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.050781; w_down is frozen during training so its norm stays constant
2025-11-14 16:59:56 (IST) - 0:04:38 - train - INFO - [TTT] Step 40: grad_norm=4.238e-08, param_norm=1.2560, delta_norm=4.882e-03, relative_change=0.3887% (6 params)
2025-11-14 16:59:56 (IST) - 0:04:38 - train - INFO - step: 000040 - done (%): 2.0 - loss: 4.981 - lr: 3.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.2 - avg_words_per_second: 5108.4 - ETA: >2025-11-14 20:35:45
2025-11-14 16:59:56 (IST) - 0:04:39 - train - INFO - [DocStream] step=41 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=2-3]
2025-11-14 17:00:02 (IST) - 0:04:44 - train - INFO - [TTT] Step 41: grad_norm=9.510e-08, param_norm=1.2564, delta_norm=4.821e-03, relative_change=0.3837% (6 params)
2025-11-14 17:00:02 (IST) - 0:04:44 - train - INFO - step: 000041 - done (%): 2.0 - loss: 3.974 - lr: 3.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5380.6 - avg_words_per_second: 5114.7 - ETA: >2025-11-14 20:35:29
2025-11-14 17:00:02 (IST) - 0:04:45 - train - INFO - [DocStream] step=42 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=4-5]
2025-11-14 17:00:08 (IST) - 0:04:51 - train - INFO - [TTT] Step 42: grad_norm=2.515e-08, param_norm=1.2568, delta_norm=4.753e-03, relative_change=0.3781% (6 params)
2025-11-14 17:00:08 (IST) - 0:04:51 - train - INFO - step: 000042 - done (%): 2.1 - loss: 3.739 - lr: 3.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5356.4 - avg_words_per_second: 5120.2 - ETA: >2025-11-14 20:35:15
2025-11-14 17:00:09 (IST) - 0:04:51 - train - INFO - [DocStream] step=43 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=6-7]
2025-11-14 17:00:15 (IST) - 0:04:57 - train - INFO - [TTT] Step 43: grad_norm=2.673e-08, param_norm=1.2571, delta_norm=4.818e-03, relative_change=0.3833% (6 params)
2025-11-14 17:00:15 (IST) - 0:04:57 - train - INFO - step: 000043 - done (%): 2.1 - loss: 1.905 - lr: 4.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5364.7 - avg_words_per_second: 5125.6 - ETA: >2025-11-14 20:35:01
2025-11-14 17:00:15 (IST) - 0:04:57 - train - INFO - [DocStream] step=44 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=8-9]
2025-11-14 17:00:21 (IST) - 0:05:03 - train - INFO - [TTT] Step 44: grad_norm=2.764e-08, param_norm=1.2574, delta_norm=4.957e-03, relative_change=0.3943% (6 params)
2025-11-14 17:00:21 (IST) - 0:05:03 - train - INFO - step: 000044 - done (%): 2.2 - loss: 2.634 - lr: 4.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5371.0 - avg_words_per_second: 5131.0 - ETA: >2025-11-14 20:34:47
2025-11-14 17:00:21 (IST) - 0:05:04 - train - INFO - [DocStream] step=45 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=10-11]
2025-11-14 17:00:27 (IST) - 0:05:10 - train - INFO - [TTT] Step 45: grad_norm=2.524e-08, param_norm=1.2576, delta_norm=5.255e-03, relative_change=0.4178% (6 params)
2025-11-14 17:00:27 (IST) - 0:05:10 - train - INFO - step: 000045 - done (%): 2.2 - loss: 2.330 - lr: 4.4e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5363.5 - avg_words_per_second: 5135.9 - ETA: >2025-11-14 20:34:34
2025-11-14 17:00:28 (IST) - 0:05:10 - train - INFO - [DocStream] step=46 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=0-1]
2025-11-14 17:00:28 (IST) - 0:05:10 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4145.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4156.wav
2025-11-14 17:00:28 (IST) - 0:05:10 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 17:00:28 (IST) - 0:05:10 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.000000; w_down is frozen during training so its norm stays constant
2025-11-14 17:00:28 (IST) - 0:05:10 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.054688; w_down is frozen during training so its norm stays constant
2025-11-14 17:00:34 (IST) - 0:05:16 - train - INFO - [TTT] Step 46: grad_norm=6.157e-08, param_norm=1.2578, delta_norm=5.687e-03, relative_change=0.4521% (6 params)
2025-11-14 17:00:34 (IST) - 0:05:16 - train - INFO - step: 000046 - done (%): 2.3 - loss: 4.402 - lr: 4.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5372.2 - avg_words_per_second: 5140.8 - ETA: >2025-11-14 20:34:22
2025-11-14 17:00:34 (IST) - 0:05:16 - train - INFO - [DocStream] step=47 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=2-3]
2025-11-14 17:00:40 (IST) - 0:05:22 - train - INFO - [TTT] Step 47: grad_norm=4.828e-08, param_norm=1.2580, delta_norm=6.544e-03, relative_change=0.5202% (6 params)
2025-11-14 17:00:40 (IST) - 0:05:22 - train - INFO - step: 000047 - done (%): 2.4 - loss: 4.790 - lr: 4.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5367.0 - avg_words_per_second: 5145.4 - ETA: >2025-11-14 20:34:10
2025-11-14 17:00:40 (IST) - 0:05:23 - train - INFO - [DocStream] step=48 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=4-5]
2025-11-14 17:00:46 (IST) - 0:05:29 - train - INFO - [TTT] Step 48: grad_norm=6.339e-08, param_norm=1.2581, delta_norm=8.069e-03, relative_change=0.6414% (6 params)
2025-11-14 17:00:46 (IST) - 0:05:29 - train - INFO - step: 000048 - done (%): 2.4 - loss: 4.998 - lr: 4.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5362.3 - avg_words_per_second: 5149.8 - ETA: >2025-11-14 20:33:59
2025-11-14 17:00:46 (IST) - 0:05:29 - train - INFO - [DocStream] step=49 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=6-7]
2025-11-14 17:00:52 (IST) - 0:05:35 - train - INFO - [TTT] Step 49: grad_norm=4.566e-08, param_norm=1.2582, delta_norm=9.048e-03, relative_change=0.7191% (6 params)
2025-11-14 17:00:52 (IST) - 0:05:35 - train - INFO - step: 000049 - done (%): 2.5 - loss: 5.164 - lr: 5.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5368.8 - avg_words_per_second: 5154.1 - ETA: >2025-11-14 20:33:48
2025-11-14 17:00:53 (IST) - 0:05:35 - train - INFO - [DocStream] step=50 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=8-9]
2025-11-14 17:00:59 (IST) - 0:05:41 - train - INFO - [TTT] Step 50: grad_norm=1.324e-07, param_norm=1.2583, delta_norm=1.189e-02, relative_change=0.9450% (6 params)
2025-11-14 17:00:59 (IST) - 0:05:41 - train - INFO - step: 000050 - done (%): 2.5 - loss: 4.784 - lr: 5.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5458.7 - avg_words_per_second: 5159.8 - ETA: >2025-11-14 20:33:33
2025-11-14 17:00:59 (IST) - 0:05:41 - train - INFO - [DocStream] step=51 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=0-1]
2025-11-14 17:00:59 (IST) - 0:05:41 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4156.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4157.wav
2025-11-14 17:00:59 (IST) - 0:05:41 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 17:00:59 (IST) - 0:05:41 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.001953; w_down is frozen during training so its norm stays constant
2025-11-14 17:00:59 (IST) - 0:05:41 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.058594; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:05 (IST) - 0:05:47 - train - INFO - [TTT] Step 51: grad_norm=3.023e-08, param_norm=1.2585, delta_norm=1.163e-02, relative_change=0.9238% (6 params)
2025-11-14 17:01:05 (IST) - 0:05:47 - train - INFO - step: 000051 - done (%): 2.5 - loss: 4.901 - lr: 5.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5358.1 - avg_words_per_second: 5163.6 - ETA: >2025-11-14 20:33:24
2025-11-14 17:01:05 (IST) - 0:05:48 - train - INFO - [DocStream] step=52 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=2-3]
2025-11-14 17:01:11 (IST) - 0:05:54 - train - INFO - [TTT] Step 52: grad_norm=2.920e-08, param_norm=1.2586, delta_norm=1.121e-02, relative_change=0.8909% (6 params)
2025-11-14 17:01:11 (IST) - 0:05:54 - train - INFO - step: 000052 - done (%): 2.6 - loss: 4.385 - lr: 5.4e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.7 - avg_words_per_second: 5167.4 - ETA: >2025-11-14 20:33:14
2025-11-14 17:01:11 (IST) - 0:05:54 - train - INFO - [DocStream] step=53 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=4-5]
2025-11-14 17:01:17 (IST) - 0:06:00 - train - INFO - [TTT] Step 53: grad_norm=1.927e-08, param_norm=1.2588, delta_norm=1.010e-02, relative_change=0.8023% (6 params)
2025-11-14 17:01:17 (IST) - 0:06:00 - train - INFO - step: 000053 - done (%): 2.6 - loss: 3.942 - lr: 5.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5493.8 - avg_words_per_second: 5173.2 - ETA: >2025-11-14 20:33:00
2025-11-14 17:01:18 (IST) - 0:06:00 - train - INFO - [DocStream] step=54 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=0-1]
2025-11-14 17:01:18 (IST) - 0:06:00 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4157.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4170.wav
2025-11-14 17:01:18 (IST) - 0:06:00 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:18 (IST) - 0:06:00 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.001953; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:18 (IST) - 0:06:00 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.060547; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:24 (IST) - 0:06:06 - train - INFO - [TTT] Step 54: grad_norm=3.854e-08, param_norm=1.2589, delta_norm=9.053e-03, relative_change=0.7191% (6 params)
2025-11-14 17:01:24 (IST) - 0:06:06 - train - INFO - step: 000054 - done (%): 2.7 - loss: 4.465 - lr: 5.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5241.7 - avg_words_per_second: 5174.5 - ETA: >2025-11-14 20:32:56
2025-11-14 17:01:24 (IST) - 0:06:07 - train - INFO - [DocStream] step=55 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=2-3]
2025-11-14 17:01:30 (IST) - 0:06:12 - train - INFO - [TTT] Step 55: grad_norm=4.150e-08, param_norm=1.2590, delta_norm=8.435e-03, relative_change=0.6700% (6 params)
2025-11-14 17:01:30 (IST) - 0:06:12 - train - INFO - step: 000055 - done (%): 2.8 - loss: 4.874 - lr: 5.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5374.6 - avg_words_per_second: 5178.0 - ETA: >2025-11-14 20:32:48
2025-11-14 17:01:30 (IST) - 0:06:13 - train - INFO - [DocStream] step=56 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=4-5]
2025-11-14 17:01:36 (IST) - 0:06:19 - train - INFO - [TTT] Step 56: grad_norm=3.428e-08, param_norm=1.2591, delta_norm=8.095e-03, relative_change=0.6429% (6 params)
2025-11-14 17:01:36 (IST) - 0:06:19 - train - INFO - step: 000056 - done (%): 2.8 - loss: 5.386 - lr: 6.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.2 - avg_words_per_second: 5181.3 - ETA: >2025-11-14 20:32:39
2025-11-14 17:01:37 (IST) - 0:06:19 - train - INFO - [DocStream] step=57 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=6-7]
2025-11-14 17:01:43 (IST) - 0:06:25 - train - INFO - [TTT] Step 57: grad_norm=4.318e-08, param_norm=1.2591, delta_norm=8.843e-03, relative_change=0.7023% (6 params)
2025-11-14 17:01:43 (IST) - 0:06:25 - train - INFO - step: 000057 - done (%): 2.9 - loss: 5.059 - lr: 6.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5368.4 - avg_words_per_second: 5184.4 - ETA: >2025-11-14 20:32:31
2025-11-14 17:01:43 (IST) - 0:06:25 - train - INFO - [DocStream] step=58 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=8-9]
2025-11-14 17:01:49 (IST) - 0:06:31 - train - INFO - [TTT] Step 58: grad_norm=4.679e-08, param_norm=1.2592, delta_norm=1.018e-02, relative_change=0.8083% (6 params)
2025-11-14 17:01:49 (IST) - 0:06:31 - train - INFO - step: 000058 - done (%): 2.9 - loss: 4.862 - lr: 6.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5361.0 - avg_words_per_second: 5187.4 - ETA: >2025-11-14 20:32:24
2025-11-14 17:01:49 (IST) - 0:06:32 - train - INFO - [DocStream] step=59 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=10-11]
2025-11-14 17:01:55 (IST) - 0:06:38 - train - INFO - [TTT] Step 59: grad_norm=3.509e-08, param_norm=1.2592, delta_norm=1.097e-02, relative_change=0.8716% (6 params)
2025-11-14 17:01:55 (IST) - 0:06:38 - train - INFO - step: 000059 - done (%): 3.0 - loss: 4.906 - lr: 6.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5360.9 - avg_words_per_second: 5190.2 - ETA: >2025-11-14 20:32:17
2025-11-14 17:01:56 (IST) - 0:06:38 - train - INFO - [DocStream] step=60 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=0-1]
2025-11-14 17:01:56 (IST) - 0:06:38 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4170.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4183.wav
2025-11-14 17:01:56 (IST) - 0:06:38 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:56 (IST) - 0:06:38 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.000000; w_down is frozen during training so its norm stays constant
2025-11-14 17:01:56 (IST) - 0:06:38 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.064453; w_down is frozen during training so its norm stays constant
2025-11-14 17:02:01 (IST) - 0:06:44 - train - INFO - [TTT] Step 60: grad_norm=1.006e-07, param_norm=1.2592, delta_norm=1.473e-02, relative_change=1.1700% (6 params)
2025-11-14 17:02:01 (IST) - 0:06:44 - train - INFO - step: 000060 - done (%): 3.0 - loss: 4.430 - lr: 6.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5361.1 - avg_words_per_second: 5193.0 - ETA: >2025-11-14 20:32:10
2025-11-14 17:02:02 (IST) - 0:06:44 - train - INFO - [DocStream] step=61 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=2-3]
2025-11-14 17:02:08 (IST) - 0:06:50 - train - INFO - [TTT] Step 61: grad_norm=5.371e-08, param_norm=1.2593, delta_norm=1.525e-02, relative_change=1.2111% (6 params)
2025-11-14 17:02:08 (IST) - 0:06:50 - train - INFO - step: 000061 - done (%): 3.0 - loss: 4.377 - lr: 6.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5362.4 - avg_words_per_second: 5195.7 - ETA: >2025-11-14 20:32:03
2025-11-14 17:02:08 (IST) - 0:06:51 - train - INFO - [DocStream] step=62 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=4-5]
2025-11-14 17:02:14 (IST) - 0:06:57 - train - INFO - [TTT] Step 62: grad_norm=5.122e-08, param_norm=1.2595, delta_norm=1.653e-02, relative_change=1.3123% (6 params)
2025-11-14 17:02:14 (IST) - 0:06:57 - train - INFO - step: 000062 - done (%): 3.1 - loss: 4.349 - lr: 6.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5360.4 - avg_words_per_second: 5198.3 - ETA: >2025-11-14 20:31:57
2025-11-14 17:02:15 (IST) - 0:06:57 - train - INFO - [DocStream] step=63 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=6-7]
2025-11-14 17:02:21 (IST) - 0:07:03 - train - INFO - [TTT] Step 63: grad_norm=5.675e-08, param_norm=1.2598, delta_norm=1.827e-02, relative_change=1.4503% (6 params)
2025-11-14 17:02:21 (IST) - 0:07:03 - train - INFO - step: 000063 - done (%): 3.1 - loss: 4.373 - lr: 7.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5238.3 - avg_words_per_second: 5198.9 - ETA: >2025-11-14 20:31:55
2025-11-14 17:02:21 (IST) - 0:07:03 - train - INFO - [DocStream] step=64 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=8-9]
2025-11-14 17:02:27 (IST) - 0:07:09 - train - INFO - [TTT] Step 64: grad_norm=5.011e-08, param_norm=1.2602, delta_norm=1.970e-02, relative_change=1.5632% (6 params)
2025-11-14 17:02:27 (IST) - 0:07:09 - train - INFO - step: 000064 - done (%): 3.2 - loss: 4.178 - lr: 7.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5368.7 - avg_words_per_second: 5201.5 - ETA: >2025-11-14 20:31:49
2025-11-14 17:02:27 (IST) - 0:07:10 - train - INFO - [DocStream] step=65 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=10-11]
2025-11-14 17:02:33 (IST) - 0:07:16 - train - INFO - [TTT] Step 65: grad_norm=3.779e-08, param_norm=1.2607, delta_norm=2.006e-02, relative_change=1.5908% (6 params)
2025-11-14 17:02:33 (IST) - 0:07:16 - train - INFO - step: 000065 - done (%): 3.2 - loss: 4.326 - lr: 7.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.8 - avg_words_per_second: 5204.0 - ETA: >2025-11-14 20:31:42
2025-11-14 17:02:33 (IST) - 0:07:16 - train - INFO - [DocStream] step=66 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=0-1]
2025-11-14 17:02:33 (IST) - 0:07:16 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4183.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4184.wav
2025-11-14 17:02:33 (IST) - 0:07:16 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 17:02:33 (IST) - 0:07:16 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.003906; w_down is frozen during training so its norm stays constant
2025-11-14 17:02:33 (IST) - 0:07:16 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.066406; w_down is frozen during training so its norm stays constant
2025-11-14 17:02:39 (IST) - 0:07:22 - train - INFO - [TTT] Step 66: grad_norm=2.043e-08, param_norm=1.2614, delta_norm=1.700e-02, relative_change=1.3478% (6 params)
2025-11-14 17:02:39 (IST) - 0:07:22 - train - INFO - step: 000066 - done (%): 3.3 - loss: 4.735 - lr: 7.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5366.5 - avg_words_per_second: 5206.4 - ETA: >2025-11-14 20:31:36
2025-11-14 17:02:40 (IST) - 0:07:22 - train - INFO - [DocStream] step=67 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=2-3]
2025-11-14 17:02:46 (IST) - 0:07:28 - train - INFO - [TTT] Step 67: grad_norm=2.436e-08, param_norm=1.2620, delta_norm=1.432e-02, relative_change=1.1350% (6 params)
2025-11-14 17:02:46 (IST) - 0:07:28 - train - INFO - step: 000067 - done (%): 3.4 - loss: 4.651 - lr: 7.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5360.1 - avg_words_per_second: 5208.6 - ETA: >2025-11-14 20:31:31
2025-11-14 17:02:46 (IST) - 0:07:28 - train - INFO - [DocStream] step=68 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=4-5]
2025-11-14 17:02:52 (IST) - 0:07:34 - train - INFO - [TTT] Step 68: grad_norm=1.459e-08, param_norm=1.2626, delta_norm=1.206e-02, relative_change=0.9550% (6 params)
2025-11-14 17:02:52 (IST) - 0:07:34 - train - INFO - step: 000068 - done (%): 3.4 - loss: 3.139 - lr: 7.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5364.0 - avg_words_per_second: 5210.8 - ETA: >2025-11-14 20:31:25
2025-11-14 17:02:52 (IST) - 0:07:35 - train - INFO - [DocStream] step=69 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=6-7]
2025-11-14 17:02:58 (IST) - 0:07:41 - train - INFO - [TTT] Step 69: grad_norm=1.674e-08, param_norm=1.2631, delta_norm=1.045e-02, relative_change=0.8270% (6 params)
2025-11-14 17:02:58 (IST) - 0:07:41 - train - INFO - step: 000069 - done (%): 3.5 - loss: 2.804 - lr: 7.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5359.2 - avg_words_per_second: 5212.9 - ETA: >2025-11-14 20:31:20
2025-11-14 17:02:59 (IST) - 0:07:41 - train - INFO - [DocStream] step=70 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=8-9]
2025-11-14 17:03:05 (IST) - 0:07:47 - train - INFO - [TTT] Step 70: grad_norm=1.658e-08, param_norm=1.2634, delta_norm=8.916e-03, relative_change=0.7057% (6 params)
2025-11-14 17:03:05 (IST) - 0:07:47 - train - INFO - step: 000070 - done (%): 3.5 - loss: 2.880 - lr: 8.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5365.0 - avg_words_per_second: 5215.0 - ETA: >2025-11-14 20:31:15
2025-11-14 17:03:05 (IST) - 0:07:47 - train - INFO - [DocStream] step=71 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=10-11]
2025-11-14 17:03:11 (IST) - 0:07:53 - train - INFO - [TTT] Step 71: grad_norm=1.953e-08, param_norm=1.2636, delta_norm=7.926e-03, relative_change=0.6272% (6 params)
2025-11-14 17:03:11 (IST) - 0:07:53 - train - INFO - step: 000071 - done (%): 3.5 - loss: 2.195 - lr: 8.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5356.7 - avg_words_per_second: 5217.0 - ETA: >2025-11-14 20:31:10
2025-11-14 17:03:11 (IST) - 0:07:54 - train - INFO - [DocStream] step=72 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=0-1]
2025-11-14 17:03:11 (IST) - 0:07:54 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4184.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4234.wav
2025-11-14 17:03:11 (IST) - 0:07:54 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.990234; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:11 (IST) - 0:07:54 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.003906; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:11 (IST) - 0:07:54 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.070312; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:17 (IST) - 0:08:00 - train - INFO - [TTT] Step 72: grad_norm=2.795e-08, param_norm=1.2638, delta_norm=7.173e-03, relative_change=0.5676% (6 params)
2025-11-14 17:03:17 (IST) - 0:08:00 - train - INFO - step: 000072 - done (%): 3.6 - loss: 4.725 - lr: 8.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5349.3 - avg_words_per_second: 5218.8 - ETA: >2025-11-14 20:31:06
2025-11-14 17:03:18 (IST) - 0:08:00 - train - INFO - [DocStream] step=73 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=2-3]
2025-11-14 17:03:24 (IST) - 0:08:06 - train - INFO - [TTT] Step 73: grad_norm=2.073e-08, param_norm=1.2637, delta_norm=7.235e-03, relative_change=0.5725% (6 params)
2025-11-14 17:03:24 (IST) - 0:08:06 - train - INFO - step: 000073 - done (%): 3.6 - loss: 5.181 - lr: 8.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5357.0 - avg_words_per_second: 5220.6 - ETA: >2025-11-14 20:31:01
2025-11-14 17:03:24 (IST) - 0:08:06 - train - INFO - [DocStream] step=74 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=4-5]
2025-11-14 17:03:30 (IST) - 0:08:12 - train - INFO - [TTT] Step 74: grad_norm=1.639e-08, param_norm=1.2636, delta_norm=7.529e-03, relative_change=0.5958% (6 params)
2025-11-14 17:03:30 (IST) - 0:08:12 - train - INFO - step: 000074 - done (%): 3.7 - loss: 3.807 - lr: 8.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5376.1 - avg_words_per_second: 5222.7 - ETA: >2025-11-14 20:30:56
2025-11-14 17:03:30 (IST) - 0:08:13 - train - INFO - [DocStream] step=75 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=6-7]
2025-11-14 17:03:36 (IST) - 0:08:19 - train - INFO - [TTT] Step 75: grad_norm=1.456e-08, param_norm=1.2634, delta_norm=7.810e-03, relative_change=0.6182% (6 params)
2025-11-14 17:03:36 (IST) - 0:08:19 - train - INFO - step: 000075 - done (%): 3.8 - loss: 2.451 - lr: 8.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5312.3 - avg_words_per_second: 5223.8 - ETA: >2025-11-14 20:30:53
2025-11-14 17:03:36 (IST) - 0:08:19 - train - INFO - [DocStream] step=76 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=8-9]
2025-11-14 17:03:42 (IST) - 0:08:25 - train - INFO - [TTT] Step 76: grad_norm=1.591e-08, param_norm=1.2632, delta_norm=8.248e-03, relative_change=0.6530% (6 params)
2025-11-14 17:03:42 (IST) - 0:08:25 - train - INFO - step: 000076 - done (%): 3.8 - loss: 2.976 - lr: 8.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5364.4 - avg_words_per_second: 5225.6 - ETA: >2025-11-14 20:30:49
2025-11-14 17:03:43 (IST) - 0:08:25 - train - INFO - [DocStream] step=77 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=10-11]
2025-11-14 17:03:49 (IST) - 0:08:31 - train - INFO - [TTT] Step 77: grad_norm=1.409e-08, param_norm=1.2628, delta_norm=8.593e-03, relative_change=0.6805% (6 params)
2025-11-14 17:03:49 (IST) - 0:08:31 - train - INFO - step: 000077 - done (%): 3.9 - loss: 2.770 - lr: 8.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5373.0 - avg_words_per_second: 5227.5 - ETA: >2025-11-14 20:30:44
2025-11-14 17:03:49 (IST) - 0:08:32 - train - INFO - [DocStream] step=78 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=0-1]
2025-11-14 17:03:49 (IST) - 0:08:32 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4234.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4245.wav
2025-11-14 17:03:49 (IST) - 0:08:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:49 (IST) - 0:08:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.003906; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:49 (IST) - 0:08:32 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.076172; w_down is frozen during training so its norm stays constant
2025-11-14 17:03:55 (IST) - 0:08:37 - train - INFO - [TTT] Step 78: grad_norm=2.122e-08, param_norm=1.2624, delta_norm=8.423e-03, relative_change=0.6672% (6 params)
2025-11-14 17:03:55 (IST) - 0:08:37 - train - INFO - step: 000078 - done (%): 3.9 - loss: 5.301 - lr: 8.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5366.4 - avg_words_per_second: 5229.2 - ETA: >2025-11-14 20:30:40
2025-11-14 17:03:55 (IST) - 0:08:38 - train - INFO - [DocStream] step=79 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=2-3]
2025-11-14 17:04:01 (IST) - 0:08:44 - train - INFO - [TTT] Step 79: grad_norm=2.036e-08, param_norm=1.2620, delta_norm=8.681e-03, relative_change=0.6878% (6 params)
2025-11-14 17:04:01 (IST) - 0:08:44 - train - INFO - step: 000079 - done (%): 4.0 - loss: 5.473 - lr: 9.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5372.2 - avg_words_per_second: 5231.0 - ETA: >2025-11-14 20:30:35
2025-11-14 17:04:02 (IST) - 0:08:44 - train - INFO - [DocStream] step=80 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=4-5]
2025-11-14 17:04:08 (IST) - 0:08:50 - train - INFO - [TTT] Step 80: grad_norm=1.575e-08, param_norm=1.2615, delta_norm=8.928e-03, relative_change=0.7077% (6 params)
2025-11-14 17:04:08 (IST) - 0:08:50 - train - INFO - step: 000080 - done (%): 4.0 - loss: 4.312 - lr: 9.1e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5361.8 - avg_words_per_second: 5232.6 - ETA: >2025-11-14 20:30:32
2025-11-14 17:04:08 (IST) - 0:08:50 - train - INFO - [DocStream] step=81 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=6-7]
2025-11-14 17:04:14 (IST) - 0:08:56 - train - INFO - [TTT] Step 81: grad_norm=1.594e-08, param_norm=1.2610, delta_norm=9.299e-03, relative_change=0.7374% (6 params)
2025-11-14 17:04:14 (IST) - 0:08:56 - train - INFO - step: 000081 - done (%): 4.0 - loss: 3.087 - lr: 9.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5373.5 - avg_words_per_second: 5234.3 - ETA: >2025-11-14 20:30:27
2025-11-14 17:04:14 (IST) - 0:08:57 - train - INFO - [DocStream] step=82 microbatch=0 samples=2 unique_docs=2 runs=4245.wav[segment=8], 4247.wav[segment=0]
2025-11-14 17:04:14 (IST) - 0:08:57 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4245.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4247.wav
2025-11-14 17:04:14 (IST) - 0:08:57 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:14 (IST) - 0:08:57 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.003906; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:14 (IST) - 0:08:57 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.072266; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:20 (IST) - 0:09:03 - train - INFO - [TTT] Step 82: grad_norm=1.375e-08, param_norm=1.2604, delta_norm=9.174e-03, relative_change=0.7279% (6 params)
2025-11-14 17:04:20 (IST) - 0:09:03 - train - INFO - step: 000082 - done (%): 4.1 - loss: 4.169 - lr: 9.2e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5418.7 - avg_words_per_second: 5236.5 - ETA: >2025-11-14 20:30:22
2025-11-14 17:04:20 (IST) - 0:09:03 - train - INFO - [DocStream] step=83 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=1-2]
2025-11-14 17:04:26 (IST) - 0:09:09 - train - INFO - [TTT] Step 83: grad_norm=1.942e-08, param_norm=1.2598, delta_norm=9.268e-03, relative_change=0.7357% (6 params)
2025-11-14 17:04:26 (IST) - 0:09:09 - train - INFO - step: 000083 - done (%): 4.2 - loss: 4.700 - lr: 9.3e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5361.4 - avg_words_per_second: 5237.9 - ETA: >2025-11-14 20:30:18
2025-11-14 17:04:27 (IST) - 0:09:09 - train - INFO - [DocStream] step=84 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=3-4]
2025-11-14 17:04:33 (IST) - 0:09:15 - train - INFO - [TTT] Step 84: grad_norm=1.564e-08, param_norm=1.2592, delta_norm=9.558e-03, relative_change=0.7590% (6 params)
2025-11-14 17:04:33 (IST) - 0:09:15 - train - INFO - step: 000084 - done (%): 4.2 - loss: 3.916 - lr: 9.4e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5345.6 - avg_words_per_second: 5239.2 - ETA: >2025-11-14 20:30:15
2025-11-14 17:04:33 (IST) - 0:09:16 - train - INFO - [DocStream] step=85 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=5-6]
2025-11-14 17:04:39 (IST) - 0:09:21 - train - INFO - [TTT] Step 85: grad_norm=1.163e-08, param_norm=1.2586, delta_norm=9.235e-03, relative_change=0.7337% (6 params)
2025-11-14 17:04:39 (IST) - 0:09:21 - train - INFO - step: 000085 - done (%): 4.2 - loss: 2.116 - lr: 9.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5375.0 - avg_words_per_second: 5240.7 - ETA: >2025-11-14 20:30:11
2025-11-14 17:04:39 (IST) - 0:09:22 - train - INFO - [DocStream] step=86 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=7-8]
2025-11-14 17:04:45 (IST) - 0:09:28 - train - INFO - [TTT] Step 86: grad_norm=1.098e-08, param_norm=1.2579, delta_norm=9.011e-03, relative_change=0.7163% (6 params)
2025-11-14 17:04:45 (IST) - 0:09:28 - train - INFO - step: 000086 - done (%): 4.3 - loss: 2.578 - lr: 9.5e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5366.5 - avg_words_per_second: 5242.2 - ETA: >2025-11-14 20:30:08
2025-11-14 17:04:46 (IST) - 0:09:28 - train - INFO - [DocStream] step=87 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=9-10]
2025-11-14 17:04:52 (IST) - 0:09:34 - train - INFO - [TTT] Step 87: grad_norm=1.344e-08, param_norm=1.2572, delta_norm=9.014e-03, relative_change=0.7170% (6 params)
2025-11-14 17:04:52 (IST) - 0:09:34 - train - INFO - step: 000087 - done (%): 4.3 - loss: 2.648 - lr: 9.6e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5375.2 - avg_words_per_second: 5243.7 - ETA: >2025-11-14 20:30:04
2025-11-14 17:04:52 (IST) - 0:09:34 - train - INFO - [DocStream] step=88 microbatch=0 samples=2 unique_docs=2 runs=4247.wav[segment=11], 4248.wav[segment=0]
2025-11-14 17:04:52 (IST) - 0:09:34 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4247.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4248.wav
2025-11-14 17:04:52 (IST) - 0:09:34 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.984375; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:52 (IST) - 0:09:34 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.000000; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:52 (IST) - 0:09:34 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.070312; w_down is frozen during training so its norm stays constant
2025-11-14 17:04:58 (IST) - 0:09:40 - train - INFO - [TTT] Step 88: grad_norm=1.250e-08, param_norm=1.2565, delta_norm=8.746e-03, relative_change=0.6961% (6 params)
2025-11-14 17:04:58 (IST) - 0:09:40 - train - INFO - step: 000088 - done (%): 4.4 - loss: 4.109 - lr: 9.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5374.0 - avg_words_per_second: 5245.1 - ETA: >2025-11-14 20:30:01
2025-11-14 17:04:58 (IST) - 0:09:41 - train - INFO - [DocStream] step=89 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=1-2]
2025-11-14 17:05:04 (IST) - 0:09:47 - train - INFO - [TTT] Step 89: grad_norm=2.716e-08, param_norm=1.2558, delta_norm=8.996e-03, relative_change=0.7163% (6 params)
2025-11-14 17:05:04 (IST) - 0:09:47 - train - INFO - step: 000089 - done (%): 4.5 - loss: 4.855 - lr: 9.7e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5368.7 - avg_words_per_second: 5246.5 - ETA: >2025-11-14 20:29:57
2025-11-14 17:05:04 (IST) - 0:09:47 - train - INFO - [DocStream] step=90 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=3-4]
2025-11-14 17:05:10 (IST) - 0:09:53 - train - INFO - [TTT] Step 90: grad_norm=2.630e-08, param_norm=1.2551, delta_norm=9.613e-03, relative_change=0.7659% (6 params)
2025-11-14 17:05:10 (IST) - 0:09:53 - train - INFO - step: 000090 - done (%): 4.5 - loss: 4.131 - lr: 9.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.9 - avg_words_per_second: 5248.0 - ETA: >2025-11-14 20:29:54
2025-11-14 17:05:11 (IST) - 0:09:53 - train - INFO - [DocStream] step=91 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=5-6]
2025-11-14 17:05:17 (IST) - 0:09:59 - train - INFO - [TTT] Step 91: grad_norm=1.221e-08, param_norm=1.2543, delta_norm=9.076e-03, relative_change=0.7236% (6 params)
2025-11-14 17:05:17 (IST) - 0:09:59 - train - INFO - step: 000091 - done (%): 4.5 - loss: 2.828 - lr: 9.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5377.7 - avg_words_per_second: 5249.3 - ETA: >2025-11-14 20:29:50
2025-11-14 17:05:17 (IST) - 0:09:59 - train - INFO - [DocStream] step=92 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=7-8]
2025-11-14 17:05:23 (IST) - 0:10:05 - train - INFO - [TTT] Step 92: grad_norm=1.001e-08, param_norm=1.2536, delta_norm=8.482e-03, relative_change=0.6767% (6 params)
2025-11-14 17:05:23 (IST) - 0:10:05 - train - INFO - step: 000092 - done (%): 4.6 - loss: 2.461 - lr: 9.8e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5367.8 - avg_words_per_second: 5250.6 - ETA: >2025-11-14 20:29:47
2025-11-14 17:05:23 (IST) - 0:10:06 - train - INFO - [DocStream] step=93 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=9-10]
2025-11-14 17:05:29 (IST) - 0:10:12 - train - INFO - [TTT] Step 93: grad_norm=1.167e-08, param_norm=1.2528, delta_norm=8.152e-03, relative_change=0.6507% (6 params)
2025-11-14 17:05:29 (IST) - 0:10:12 - train - INFO - step: 000093 - done (%): 4.7 - loss: 2.780 - lr: 9.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5365.1 - avg_words_per_second: 5251.8 - ETA: >2025-11-14 20:29:44
2025-11-14 17:05:30 (IST) - 0:10:12 - train - INFO - [DocStream] step=94 microbatch=0 samples=2 unique_docs=2 runs=4248.wav[segment=11], 4289.wav[segment=0]
2025-11-14 17:05:30 (IST) - 0:10:12 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4248.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4289.wav
2025-11-14 17:05:30 (IST) - 0:10:12 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.980469; w_down is frozen during training so its norm stays constant
2025-11-14 17:05:30 (IST) - 0:10:12 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.994141; w_down is frozen during training so its norm stays constant
2025-11-14 17:05:30 (IST) - 0:10:12 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.070312; w_down is frozen during training so its norm stays constant
2025-11-14 17:05:36 (IST) - 0:10:18 - train - INFO - [TTT] Step 94: grad_norm=4.188e-08, param_norm=1.2520, delta_norm=8.861e-03, relative_change=0.7078% (6 params)
2025-11-14 17:05:36 (IST) - 0:10:18 - train - INFO - step: 000094 - done (%): 4.7 - loss: 3.212 - lr: 9.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5370.3 - avg_words_per_second: 5253.0 - ETA: >2025-11-14 20:29:41
2025-11-14 17:05:36 (IST) - 0:10:18 - train - INFO - [DocStream] step=95 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=1-2]
2025-11-14 17:05:42 (IST) - 0:10:24 - train - INFO - [TTT] Step 95: grad_norm=1.871e-08, param_norm=1.2512, delta_norm=9.654e-03, relative_change=0.7716% (6 params)
2025-11-14 17:05:42 (IST) - 0:10:24 - train - INFO - step: 000095 - done (%): 4.8 - loss: 2.368 - lr: 9.9e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5379.8 - avg_words_per_second: 5254.3 - ETA: >2025-11-14 20:29:38
2025-11-14 17:05:42 (IST) - 0:10:25 - train - INFO - [DocStream] step=96 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=3-4]
2025-11-14 17:05:48 (IST) - 0:10:31 - train - INFO - [TTT] Step 96: grad_norm=7.412e-09, param_norm=1.2503, delta_norm=8.125e-03, relative_change=0.6498% (6 params)
2025-11-14 17:05:48 (IST) - 0:10:31 - train - INFO - step: 000096 - done (%): 4.8 - loss: 1.117 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5382.4 - avg_words_per_second: 5255.6 - ETA: >2025-11-14 20:29:35
2025-11-14 17:05:48 (IST) - 0:10:31 - train - INFO - [DocStream] step=97 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=5-6]
2025-11-14 17:05:54 (IST) - 0:10:37 - train - INFO - [TTT] Step 97: grad_norm=8.708e-09, param_norm=1.2495, delta_norm=6.845e-03, relative_change=0.5478% (6 params)
2025-11-14 17:05:54 (IST) - 0:10:37 - train - INFO - step: 000097 - done (%): 4.8 - loss: 0.906 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5376.5 - avg_words_per_second: 5256.9 - ETA: >2025-11-14 20:29:32
2025-11-14 17:05:55 (IST) - 0:10:37 - train - INFO - [DocStream] step=98 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=7-8]
2025-11-14 17:06:01 (IST) - 0:10:43 - train - INFO - [TTT] Step 98: grad_norm=7.227e-09, param_norm=1.2486, delta_norm=6.231e-03, relative_change=0.4990% (6 params)
2025-11-14 17:06:01 (IST) - 0:10:43 - train - INFO - step: 000098 - done (%): 4.9 - loss: 1.402 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5366.6 - avg_words_per_second: 5258.0 - ETA: >2025-11-14 20:29:29
2025-11-14 17:06:01 (IST) - 0:10:43 - train - INFO - [DocStream] step=99 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=9-10]
2025-11-14 17:06:07 (IST) - 0:10:49 - train - INFO - [TTT] Step 99: grad_norm=9.097e-09, param_norm=1.2477, delta_norm=5.796e-03, relative_change=0.4646% (6 params)
2025-11-14 17:06:07 (IST) - 0:10:49 - train - INFO - step: 000099 - done (%): 5.0 - loss: 1.453 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5388.1 - avg_words_per_second: 5259.2 - ETA: >2025-11-14 20:29:26
2025-11-14 17:06:07 (IST) - 0:10:50 - train - INFO - [DocStream] step=100 microbatch=0 samples=2 unique_docs=2 runs=4289.wav[segment=11], 4290.wav[segment=0]
2025-11-14 17:06:07 (IST) - 0:10:50 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4289.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4290.wav
2025-11-14 17:06:07 (IST) - 0:10:50 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.978516; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:07 (IST) - 0:10:50 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.994141; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:07 (IST) - 0:10:50 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.066406; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:13 (IST) - 0:10:56 - train - INFO - [TTT] Step 100: grad_norm=1.015e-08, param_norm=1.2468, delta_norm=5.039e-03, relative_change=0.4041% (6 params)
2025-11-14 17:06:13 (IST) - 0:10:56 - train - INFO - step: 000100 - done (%): 5.0 - loss: 3.247 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5366.0 - avg_words_per_second: 5260.3 - ETA: >2025-11-14 20:29:24
2025-11-14 17:06:13 (IST) - 0:10:56 - checkpointing - INFO - Dumping checkpoint in /sise/eliyanac-group/ron_al/ttt_training_run2/checkpoints/checkpoint_000100/consolidated using tmp name: tmp.consolidated
2025-11-14 17:06:15 (IST) - 0:10:57 - checkpointing - INFO - Done dumping checkpoint in /sise/eliyanac-group/ron_al/ttt_training_run2/checkpoints/checkpoint_000100/consolidated for step: 100
2025-11-14 17:06:15 (IST) - 0:10:57 - checkpointing - INFO - Done deleting checkpoints 
2025-11-14 17:06:15 (IST) - 0:10:57 - checkpointing - INFO - Done!
2025-11-14 17:06:15 (IST) - 0:10:57 - train - INFO - [DocStream] step=101 microbatch=0 samples=2 unique_docs=1 runs=4290.wav[segments=1-2]
2025-11-14 17:06:21 (IST) - 0:11:03 - train - INFO - [TTT] Step 101: grad_norm=1.590e-08, param_norm=1.2458, delta_norm=5.518e-03, relative_change=0.4429% (6 params)
2025-11-14 17:06:21 (IST) - 0:11:03 - train - INFO - step: 000101 - done (%): 5.0 - loss: 3.399 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.0 - avg_words_per_second: 5261.5 - ETA: >2025-11-14 20:29:22
2025-11-14 17:06:21 (IST) - 0:11:04 - train - INFO - [DocStream] step=102 microbatch=0 samples=2 unique_docs=1 runs=4290.wav[segments=3-4]
2025-11-14 17:06:27 (IST) - 0:11:10 - train - INFO - [TTT] Step 102: grad_norm=9.327e-09, param_norm=1.2449, delta_norm=4.983e-03, relative_change=0.4003% (6 params)
2025-11-14 17:06:27 (IST) - 0:11:10 - train - INFO - step: 000102 - done (%): 5.1 - loss: 1.848 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5382.3 - avg_words_per_second: 5262.6 - ETA: >2025-11-14 20:29:19
2025-11-14 17:06:27 (IST) - 0:11:10 - train - INFO - [DocStream] step=103 microbatch=0 samples=2 unique_docs=1 runs=4290.wav[segments=5-6]
2025-11-14 17:06:33 (IST) - 0:11:16 - train - INFO - [TTT] Step 103: grad_norm=8.557e-09, param_norm=1.2439, delta_norm=4.882e-03, relative_change=0.3925% (6 params)
2025-11-14 17:06:33 (IST) - 0:11:16 - train - INFO - step: 000103 - done (%): 5.2 - loss: 2.010 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5381.4 - avg_words_per_second: 5263.8 - ETA: >2025-11-14 20:29:17
2025-11-14 17:06:34 (IST) - 0:11:16 - train - INFO - [DocStream] step=104 microbatch=0 samples=2 unique_docs=1 runs=4290.wav[segments=7-8]
2025-11-14 17:06:40 (IST) - 0:11:22 - train - INFO - [TTT] Step 104: grad_norm=1.099e-08, param_norm=1.2428, delta_norm=5.003e-03, relative_change=0.4025% (6 params)
2025-11-14 17:06:40 (IST) - 0:11:22 - train - INFO - step: 000104 - done (%): 5.2 - loss: 2.885 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5389.5 - avg_words_per_second: 5264.9 - ETA: >2025-11-14 20:29:14
2025-11-14 17:06:40 (IST) - 0:11:22 - train - INFO - [DocStream] step=105 microbatch=0 samples=2 unique_docs=1 runs=4290.wav[segments=9-10]
2025-11-14 17:06:46 (IST) - 0:11:28 - train - INFO - [TTT] Step 105: grad_norm=1.452e-08, param_norm=1.2418, delta_norm=5.728e-03, relative_change=0.4613% (6 params)
2025-11-14 17:06:46 (IST) - 0:11:28 - train - INFO - step: 000105 - done (%): 5.2 - loss: 2.924 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5380.8 - avg_words_per_second: 5266.0 - ETA: >2025-11-14 20:29:11
2025-11-14 17:06:46 (IST) - 0:11:29 - train - INFO - [DocStream] step=106 microbatch=0 samples=2 unique_docs=2 runs=4290.wav[segment=11], 4310.wav[segment=0]
2025-11-14 17:06:46 (IST) - 0:11:29 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4290.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4310.wav
2025-11-14 17:06:46 (IST) - 0:11:29 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.972656; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:46 (IST) - 0:11:29 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.988281; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:46 (IST) - 0:11:29 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.062500; w_down is frozen during training so its norm stays constant
2025-11-14 17:06:52 (IST) - 0:11:35 - train - INFO - [TTT] Step 106: grad_norm=1.557e-08, param_norm=1.2408, delta_norm=6.421e-03, relative_change=0.5175% (6 params)
2025-11-14 17:06:52 (IST) - 0:11:35 - train - INFO - step: 000106 - done (%): 5.3 - loss: 4.148 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5390.9 - avg_words_per_second: 5267.2 - ETA: >2025-11-14 20:29:08
2025-11-14 17:06:53 (IST) - 0:11:35 - train - INFO - [DocStream] step=107 microbatch=0 samples=2 unique_docs=1 runs=4310.wav[segments=1-2]
2025-11-14 17:06:59 (IST) - 0:11:41 - train - INFO - [TTT] Step 107: grad_norm=1.791e-08, param_norm=1.2397, delta_norm=6.736e-03, relative_change=0.5433% (6 params)
2025-11-14 17:06:59 (IST) - 0:11:41 - train - INFO - step: 000107 - done (%): 5.3 - loss: 5.253 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5373.7 - avg_words_per_second: 5268.2 - ETA: >2025-11-14 20:29:06
2025-11-14 17:06:59 (IST) - 0:11:41 - train - INFO - [DocStream] step=108 microbatch=0 samples=2 unique_docs=1 runs=4310.wav[segments=3-4]
2025-11-14 17:07:05 (IST) - 0:11:47 - train - INFO - [TTT] Step 108: grad_norm=1.400e-08, param_norm=1.2387, delta_norm=6.730e-03, relative_change=0.5433% (6 params)
2025-11-14 17:07:05 (IST) - 0:11:47 - train - INFO - step: 000108 - done (%): 5.4 - loss: 4.964 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5377.2 - avg_words_per_second: 5269.1 - ETA: >2025-11-14 20:29:04
2025-11-14 17:07:05 (IST) - 0:11:48 - train - INFO - [DocStream] step=109 microbatch=0 samples=2 unique_docs=1 runs=4310.wav[segments=5-6]
2025-11-14 17:07:11 (IST) - 0:11:54 - train - INFO - [TTT] Step 109: grad_norm=1.476e-08, param_norm=1.2377, delta_norm=7.334e-03, relative_change=0.5925% (6 params)
2025-11-14 17:07:11 (IST) - 0:11:54 - train - INFO - step: 000109 - done (%): 5.5 - loss: 4.013 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.1 - avg_words_per_second: 5270.2 - ETA: >2025-11-14 20:29:01
2025-11-14 17:07:11 (IST) - 0:11:54 - train - INFO - [DocStream] step=110 microbatch=0 samples=2 unique_docs=1 runs=4310.wav[segments=7-8]
2025-11-14 17:07:17 (IST) - 0:12:00 - train - INFO - [TTT] Step 110: grad_norm=1.384e-08, param_norm=1.2367, delta_norm=7.717e-03, relative_change=0.6240% (6 params)
2025-11-14 17:07:17 (IST) - 0:12:00 - train - INFO - step: 000110 - done (%): 5.5 - loss: 2.976 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5381.0 - avg_words_per_second: 5271.2 - ETA: >2025-11-14 20:28:59
2025-11-14 17:07:18 (IST) - 0:12:00 - train - INFO - [DocStream] step=111 microbatch=0 samples=2 unique_docs=1 runs=4310.wav[segments=9-10]
2025-11-14 17:07:24 (IST) - 0:12:06 - train - INFO - [TTT] Step 111: grad_norm=1.260e-08, param_norm=1.2357, delta_norm=8.015e-03, relative_change=0.6486% (6 params)
2025-11-14 17:07:24 (IST) - 0:12:06 - train - INFO - step: 000111 - done (%): 5.5 - loss: 3.107 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5510.3 - avg_words_per_second: 5273.2 - ETA: >2025-11-14 20:28:54
2025-11-14 17:07:24 (IST) - 0:12:06 - train - INFO - [DocStream] step=112 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=0-1]
2025-11-14 17:07:24 (IST) - 0:12:06 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4310.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4315.wav
2025-11-14 17:07:24 (IST) - 0:12:06 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.966797; w_down is frozen during training so its norm stays constant
2025-11-14 17:07:24 (IST) - 0:12:06 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.982422; w_down is frozen during training so its norm stays constant
2025-11-14 17:07:24 (IST) - 0:12:06 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.056641; w_down is frozen during training so its norm stays constant
2025-11-14 17:07:30 (IST) - 0:12:12 - train - INFO - [TTT] Step 112: grad_norm=2.642e-08, param_norm=1.2347, delta_norm=6.510e-03, relative_change=0.5272% (6 params)
2025-11-14 17:07:30 (IST) - 0:12:12 - train - INFO - step: 000112 - done (%): 5.6 - loss: 4.802 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5369.9 - avg_words_per_second: 5274.1 - ETA: >2025-11-14 20:28:52
2025-11-14 17:07:30 (IST) - 0:12:13 - train - INFO - [DocStream] step=113 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=2-3]
2025-11-14 17:07:36 (IST) - 0:12:19 - train - INFO - [TTT] Step 113: grad_norm=3.045e-08, param_norm=1.2337, delta_norm=6.984e-03, relative_change=0.5661% (6 params)
2025-11-14 17:07:36 (IST) - 0:12:19 - train - INFO - step: 000113 - done (%): 5.7 - loss: 4.426 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5364.9 - avg_words_per_second: 5274.9 - ETA: >2025-11-14 20:28:50
2025-11-14 17:07:36 (IST) - 0:12:19 - train - INFO - [DocStream] step=114 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=4-5]
2025-11-14 17:07:42 (IST) - 0:12:25 - train - INFO - [TTT] Step 114: grad_norm=1.293e-08, param_norm=1.2327, delta_norm=6.893e-03, relative_change=0.5592% (6 params)
2025-11-14 17:07:42 (IST) - 0:12:25 - train - INFO - step: 000114 - done (%): 5.7 - loss: 4.051 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5374.4 - avg_words_per_second: 5275.7 - ETA: >2025-11-14 20:28:48
2025-11-14 17:07:43 (IST) - 0:12:25 - train - INFO - [DocStream] step=115 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=6-7]
2025-11-14 17:07:49 (IST) - 0:12:31 - train - INFO - [TTT] Step 115: grad_norm=1.072e-08, param_norm=1.2317, delta_norm=6.370e-03, relative_change=0.5172% (6 params)
2025-11-14 17:07:49 (IST) - 0:12:31 - train - INFO - step: 000115 - done (%): 5.8 - loss: 2.361 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5378.7 - avg_words_per_second: 5276.6 - ETA: >2025-11-14 20:28:46
2025-11-14 17:07:49 (IST) - 0:12:31 - train - INFO - [DocStream] step=116 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=8-9]
2025-11-14 17:07:55 (IST) - 0:12:37 - train - INFO - [TTT] Step 116: grad_norm=1.085e-08, param_norm=1.2307, delta_norm=6.331e-03, relative_change=0.5144% (6 params)
2025-11-14 17:07:55 (IST) - 0:12:37 - train - INFO - step: 000116 - done (%): 5.8 - loss: 2.425 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5378.6 - avg_words_per_second: 5277.4 - ETA: >2025-11-14 20:28:43
2025-11-14 17:07:55 (IST) - 0:12:38 - train - INFO - [DocStream] step=117 microbatch=0 samples=2 unique_docs=1 runs=4315.wav[segments=10-11]
2025-11-14 17:08:01 (IST) - 0:12:44 - train - INFO - [TTT] Step 117: grad_norm=1.153e-08, param_norm=1.2297, delta_norm=6.495e-03, relative_change=0.5282% (6 params)
2025-11-14 17:08:01 (IST) - 0:12:44 - train - INFO - step: 000117 - done (%): 5.8 - loss: 2.359 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5375.1 - avg_words_per_second: 5278.3 - ETA: >2025-11-14 20:28:41
2025-11-14 17:08:02 (IST) - 0:12:44 - train - INFO - [DocStream] step=118 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=0-1]
2025-11-14 17:08:02 (IST) - 0:12:44 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4315.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4316.wav
2025-11-14 17:08:02 (IST) - 0:12:44 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.962891; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:02 (IST) - 0:12:44 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.976562; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:02 (IST) - 0:12:44 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.050781; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:08 (IST) - 0:12:50 - train - INFO - [TTT] Step 118: grad_norm=2.424e-08, param_norm=1.2287, delta_norm=6.479e-03, relative_change=0.5273% (6 params)
2025-11-14 17:08:08 (IST) - 0:12:50 - train - INFO - step: 000118 - done (%): 5.9 - loss: 3.693 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5377.8 - avg_words_per_second: 5279.1 - ETA: >2025-11-14 20:28:39
2025-11-14 17:08:08 (IST) - 0:12:50 - train - INFO - [DocStream] step=119 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=2-3]
2025-11-14 17:08:14 (IST) - 0:12:56 - train - INFO - [TTT] Step 119: grad_norm=1.343e-08, param_norm=1.2277, delta_norm=6.570e-03, relative_change=0.5352% (6 params)
2025-11-14 17:08:14 (IST) - 0:12:56 - train - INFO - step: 000119 - done (%): 6.0 - loss: 2.727 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.1 - avg_words_per_second: 5280.0 - ETA: >2025-11-14 20:28:37
2025-11-14 17:08:14 (IST) - 0:12:57 - train - INFO - [DocStream] step=120 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=4-5]
2025-11-14 17:08:20 (IST) - 0:13:03 - train - INFO - [TTT] Step 120: grad_norm=1.576e-08, param_norm=1.2266, delta_norm=6.930e-03, relative_change=0.5649% (6 params)
2025-11-14 17:08:20 (IST) - 0:13:03 - train - INFO - step: 000120 - done (%): 6.0 - loss: 2.110 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5384.9 - avg_words_per_second: 5280.8 - ETA: >2025-11-14 20:28:35
2025-11-14 17:08:20 (IST) - 0:13:03 - train - INFO - [DocStream] step=121 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=6-7]
2025-11-14 17:08:26 (IST) - 0:13:09 - train - INFO - [TTT] Step 121: grad_norm=1.577e-08, param_norm=1.2256, delta_norm=7.683e-03, relative_change=0.6269% (6 params)
2025-11-14 17:08:26 (IST) - 0:13:09 - train - INFO - step: 000121 - done (%): 6.0 - loss: 2.384 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5375.5 - avg_words_per_second: 5281.6 - ETA: >2025-11-14 20:28:33
2025-11-14 17:08:27 (IST) - 0:13:09 - train - INFO - [DocStream] step=122 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=8-9]
2025-11-14 17:08:33 (IST) - 0:13:15 - train - INFO - [TTT] Step 122: grad_norm=1.516e-08, param_norm=1.2247, delta_norm=8.259e-03, relative_change=0.6744% (6 params)
2025-11-14 17:08:33 (IST) - 0:13:15 - train - INFO - step: 000122 - done (%): 6.1 - loss: 2.837 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5386.8 - avg_words_per_second: 5282.4 - ETA: >2025-11-14 20:28:31
2025-11-14 17:08:33 (IST) - 0:13:15 - train - INFO - [DocStream] step=123 microbatch=0 samples=2 unique_docs=1 runs=4316.wav[segments=10-11]
2025-11-14 17:08:39 (IST) - 0:13:21 - train - INFO - [TTT] Step 123: grad_norm=1.774e-08, param_norm=1.2237, delta_norm=9.346e-03, relative_change=0.7637% (6 params)
2025-11-14 17:08:39 (IST) - 0:13:21 - train - INFO - step: 000123 - done (%): 6.2 - loss: 1.991 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5386.9 - avg_words_per_second: 5283.3 - ETA: >2025-11-14 20:28:29
2025-11-14 17:08:39 (IST) - 0:13:22 - train - INFO - [DocStream] step=124 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=0-1]
2025-11-14 17:08:39 (IST) - 0:13:22 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4316.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4325.wav
2025-11-14 17:08:39 (IST) - 0:13:22 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.957031; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:39 (IST) - 0:13:22 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.972656; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:39 (IST) - 0:13:22 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.046875; w_down is frozen during training so its norm stays constant
2025-11-14 17:08:45 (IST) - 0:13:28 - train - INFO - [TTT] Step 124: grad_norm=8.580e-08, param_norm=1.2228, delta_norm=1.133e-02, relative_change=0.9267% (6 params)
2025-11-14 17:08:45 (IST) - 0:13:28 - train - INFO - step: 000124 - done (%): 6.2 - loss: 3.878 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5373.9 - avg_words_per_second: 5284.0 - ETA: >2025-11-14 20:28:28
2025-11-14 17:08:46 (IST) - 0:13:28 - train - INFO - [DocStream] step=125 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=2-3]
2025-11-14 17:08:51 (IST) - 0:13:34 - train - INFO - [TTT] Step 125: grad_norm=3.982e-08, param_norm=1.2219, delta_norm=1.404e-02, relative_change=1.1490% (6 params)
2025-11-14 17:08:51 (IST) - 0:13:34 - train - INFO - step: 000125 - done (%): 6.2 - loss: 3.681 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5380.0 - avg_words_per_second: 5284.7 - ETA: >2025-11-14 20:28:26
2025-11-14 17:08:52 (IST) - 0:13:34 - train - INFO - [DocStream] step=126 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=4-5]
2025-11-14 17:08:58 (IST) - 0:13:40 - train - INFO - [TTT] Step 126: grad_norm=1.675e-08, param_norm=1.2212, delta_norm=1.363e-02, relative_change=1.1164% (6 params)
2025-11-14 17:08:58 (IST) - 0:13:40 - train - INFO - step: 000126 - done (%): 6.3 - loss: 2.415 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5391.4 - avg_words_per_second: 5285.6 - ETA: >2025-11-14 20:28:24
2025-11-14 17:08:58 (IST) - 0:13:40 - train - INFO - [DocStream] step=127 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=6-7]
2025-11-14 17:09:04 (IST) - 0:13:46 - train - INFO - [TTT] Step 127: grad_norm=1.129e-08, param_norm=1.2205, delta_norm=1.184e-02, relative_change=0.9698% (6 params)
2025-11-14 17:09:04 (IST) - 0:13:46 - train - INFO - step: 000127 - done (%): 6.3 - loss: 1.628 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5385.8 - avg_words_per_second: 5286.3 - ETA: >2025-11-14 20:28:22
2025-11-14 17:09:04 (IST) - 0:13:47 - train - INFO - [DocStream] step=128 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=8-9]
2025-11-14 17:09:10 (IST) - 0:13:53 - train - INFO - [TTT] Step 128: grad_norm=1.487e-08, param_norm=1.2198, delta_norm=1.076e-02, relative_change=0.8823% (6 params)
2025-11-14 17:09:10 (IST) - 0:13:53 - train - INFO - step: 000128 - done (%): 6.4 - loss: 1.970 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.4 - avg_words_per_second: 5287.1 - ETA: >2025-11-14 20:28:20
2025-11-14 17:09:11 (IST) - 0:13:53 - train - INFO - [DocStream] step=129 microbatch=0 samples=2 unique_docs=1 runs=4325.wav[segments=10-11]
2025-11-14 17:09:17 (IST) - 0:13:59 - train - INFO - [TTT] Step 129: grad_norm=1.211e-08, param_norm=1.2191, delta_norm=9.803e-03, relative_change=0.8041% (6 params)
2025-11-14 17:09:17 (IST) - 0:13:59 - train - INFO - step: 000129 - done (%): 6.5 - loss: 1.640 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5374.6 - avg_words_per_second: 5287.7 - ETA: >2025-11-14 20:28:19
2025-11-14 17:09:17 (IST) - 0:13:59 - train - INFO - [DocStream] step=130 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=0-1]
2025-11-14 17:09:17 (IST) - 0:13:59 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4325.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4335.wav
2025-11-14 17:09:17 (IST) - 0:13:59 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.955078; w_down is frozen during training so its norm stays constant
2025-11-14 17:09:17 (IST) - 0:13:59 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.966797; w_down is frozen during training so its norm stays constant
2025-11-14 17:09:17 (IST) - 0:13:59 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.042969; w_down is frozen during training so its norm stays constant
2025-11-14 17:09:23 (IST) - 0:14:05 - train - INFO - [TTT] Step 130: grad_norm=2.356e-08, param_norm=1.2184, delta_norm=7.618e-03, relative_change=0.6252% (6 params)
2025-11-14 17:09:23 (IST) - 0:14:05 - train - INFO - step: 000130 - done (%): 6.5 - loss: 5.134 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5367.5 - avg_words_per_second: 5288.4 - ETA: >2025-11-14 20:28:17
2025-11-14 17:09:23 (IST) - 0:14:06 - train - INFO - [DocStream] step=131 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=2-3]
2025-11-14 17:09:29 (IST) - 0:14:12 - train - INFO - [TTT] Step 131: grad_norm=2.442e-08, param_norm=1.2177, delta_norm=6.971e-03, relative_change=0.5724% (6 params)
2025-11-14 17:09:29 (IST) - 0:14:12 - train - INFO - step: 000131 - done (%): 6.5 - loss: 4.922 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5379.3 - avg_words_per_second: 5289.0 - ETA: >2025-11-14 20:28:15
2025-11-14 17:09:29 (IST) - 0:14:12 - train - INFO - [DocStream] step=132 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=4-5]
2025-11-14 17:09:35 (IST) - 0:14:18 - train - INFO - [TTT] Step 132: grad_norm=1.513e-08, param_norm=1.2169, delta_norm=6.345e-03, relative_change=0.5214% (6 params)
2025-11-14 17:09:35 (IST) - 0:14:18 - train - INFO - step: 000132 - done (%): 6.6 - loss: 4.469 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5371.0 - avg_words_per_second: 5289.6 - ETA: >2025-11-14 20:28:14
2025-11-14 17:09:36 (IST) - 0:14:18 - train - INFO - [DocStream] step=133 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=6-7]
2025-11-14 17:09:42 (IST) - 0:14:24 - train - INFO - [TTT] Step 133: grad_norm=8.213e-09, param_norm=1.2161, delta_norm=5.494e-03, relative_change=0.4518% (6 params)
2025-11-14 17:09:42 (IST) - 0:14:24 - train - INFO - step: 000133 - done (%): 6.7 - loss: 2.181 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5308.3 - avg_words_per_second: 5289.8 - ETA: >2025-11-14 20:28:14
2025-11-14 17:09:42 (IST) - 0:14:25 - train - INFO - [DocStream] step=134 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=8-9]
2025-11-14 17:09:48 (IST) - 0:14:30 - train - INFO - [TTT] Step 134: grad_norm=9.673e-09, param_norm=1.2152, delta_norm=5.074e-03, relative_change=0.4175% (6 params)
2025-11-14 17:09:48 (IST) - 0:14:30 - train - INFO - step: 000134 - done (%): 6.7 - loss: 2.614 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5383.6 - avg_words_per_second: 5290.5 - ETA: >2025-11-14 20:28:12
2025-11-14 17:09:48 (IST) - 0:14:31 - train - INFO - [DocStream] step=135 microbatch=0 samples=2 unique_docs=1 runs=4335.wav[segments=10-11]
2025-11-14 17:09:54 (IST) - 0:14:37 - train - INFO - [TTT] Step 135: grad_norm=9.412e-09, param_norm=1.2144, delta_norm=4.797e-03, relative_change=0.3950% (6 params)
2025-11-14 17:09:54 (IST) - 0:14:37 - train - INFO - step: 000135 - done (%): 6.8 - loss: 1.858 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5376.4 - avg_words_per_second: 5291.1 - ETA: >2025-11-14 20:28:10
2025-11-14 17:09:55 (IST) - 0:14:37 - train - INFO - [DocStream] step=136 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=0-1]
2025-11-14 17:09:55 (IST) - 0:14:37 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4335.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4365.wav
2025-11-14 17:09:55 (IST) - 0:14:37 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.951172; w_down is frozen during training so its norm stays constant
2025-11-14 17:09:55 (IST) - 0:14:37 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.964844; w_down is frozen during training so its norm stays constant
2025-11-14 17:09:55 (IST) - 0:14:37 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.041016; w_down is frozen during training so its norm stays constant
2025-11-14 17:10:01 (IST) - 0:14:43 - train - INFO - [TTT] Step 136: grad_norm=5.896e-08, param_norm=1.2135, delta_norm=9.648e-03, relative_change=0.7951% (6 params)
2025-11-14 17:10:01 (IST) - 0:14:43 - train - INFO - step: 000136 - done (%): 6.8 - loss: 3.977 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5367.0 - avg_words_per_second: 5291.7 - ETA: >2025-11-14 20:28:09
2025-11-14 17:10:01 (IST) - 0:14:43 - train - INFO - [DocStream] step=137 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=2-3]
2025-11-14 17:10:07 (IST) - 0:14:49 - train - INFO - [TTT] Step 137: grad_norm=3.420e-08, param_norm=1.2126, delta_norm=1.226e-02, relative_change=1.0109% (6 params)
2025-11-14 17:10:07 (IST) - 0:14:49 - train - INFO - step: 000137 - done (%): 6.8 - loss: 4.313 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5365.0 - avg_words_per_second: 5292.2 - ETA: >2025-11-14 20:28:08
2025-11-14 17:10:07 (IST) - 0:14:50 - train - INFO - [DocStream] step=138 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=4-5]
2025-11-14 17:10:13 (IST) - 0:14:56 - train - INFO - [TTT] Step 138: grad_norm=1.032e-08, param_norm=1.2118, delta_norm=1.036e-02, relative_change=0.8552% (6 params)
2025-11-14 17:10:13 (IST) - 0:14:56 - train - INFO - step: 000138 - done (%): 6.9 - loss: 3.304 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5377.5 - avg_words_per_second: 5292.8 - ETA: >2025-11-14 20:28:06
2025-11-14 17:10:13 (IST) - 0:14:56 - train - INFO - [DocStream] step=139 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=6-7]
2025-11-14 17:10:19 (IST) - 0:15:02 - train - INFO - [TTT] Step 139: grad_norm=1.043e-08, param_norm=1.2110, delta_norm=8.635e-03, relative_change=0.7131% (6 params)
2025-11-14 17:10:19 (IST) - 0:15:02 - train - INFO - step: 000139 - done (%): 7.0 - loss: 2.069 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5376.3 - avg_words_per_second: 5293.4 - ETA: >2025-11-14 20:28:05
2025-11-14 17:10:20 (IST) - 0:15:02 - train - INFO - [DocStream] step=140 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=8-9]
2025-11-14 17:10:26 (IST) - 0:15:08 - train - INFO - [TTT] Step 140: grad_norm=7.692e-09, param_norm=1.2102, delta_norm=7.468e-03, relative_change=0.6171% (6 params)
2025-11-14 17:10:26 (IST) - 0:15:08 - train - INFO - step: 000140 - done (%): 7.0 - loss: 1.563 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5380.4 - avg_words_per_second: 5294.0 - ETA: >2025-11-14 20:28:04
2025-11-14 17:10:26 (IST) - 0:15:09 - train - INFO - [DocStream] step=141 microbatch=0 samples=2 unique_docs=1 runs=4365.wav[segments=10-11]
2025-11-14 17:10:32 (IST) - 0:15:14 - train - INFO - [TTT] Step 141: grad_norm=1.039e-08, param_norm=1.2094, delta_norm=6.391e-03, relative_change=0.5284% (6 params)
2025-11-14 17:10:32 (IST) - 0:15:14 - train - INFO - step: 000141 - done (%): 7.0 - loss: 1.732 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5373.7 - avg_words_per_second: 5294.5 - ETA: >2025-11-14 20:28:02
2025-11-14 17:10:32 (IST) - 0:15:15 - train - INFO - [DocStream] step=142 microbatch=0 samples=2 unique_docs=1 runs=4371.wav[segments=0-1]
2025-11-14 17:10:32 (IST) - 0:15:15 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4365.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4371.wav
2025-11-14 17:10:32 (IST) - 0:15:15 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.945312; w_down is frozen during training so its norm stays constant
2025-11-14 17:10:32 (IST) - 0:15:15 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 0.960938; w_down is frozen during training so its norm stays constant
2025-11-14 17:10:32 (IST) - 0:15:15 - moshi.modules.ttt_module - INFO - [TTT RESET][train] target_generator total norm 1.037109; w_down is frozen during training so its norm stays constant
2025-11-14 17:10:38 (IST) - 0:15:21 - train - INFO - [TTT] Step 142: grad_norm=1.846e-08, param_norm=1.2085, delta_norm=6.570e-03, relative_change=0.5436% (6 params)
2025-11-14 17:10:38 (IST) - 0:15:21 - train - INFO - step: 000142 - done (%): 7.1 - loss: 5.320 - lr: 1.0e-02 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5378.2 - avg_words_per_second: 5295.1 - ETA: >2025-11-14 20:28:01
2025-11-14 17:10:38 (IST) - 0:15:21 - utils - INFO - Closing: eval_logger
2025-11-14 17:10:39 (IST) - 0:15:22 - utils - ERROR - Error while closing eval_logger!
2025-11-14 17:10:39 (IST) - 0:15:22 - utils - INFO - Closing: metrics_logger
2025-11-14 17:10:39 (IST) - 0:15:22 - utils - ERROR - Error while closing metrics_logger!
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mrun2[0m at: [34mhttps://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/51obu975[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../../sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_165523-51obu975/logs[0m
==================================================
Job finished at: Fri 14 Nov 2025 17:10:43 IST
==================================================
