==================================================
Job started at: Fri 14 Nov 2025 16:13:40 IST
Running on node: cs-6000-03.auth.ad.bgu.ac.il
GPU info:
Fri Nov 14 16:13:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:81:00.0 Off |                  Off |
| 30%   32C    P8             28W /  300W |       2MiB /  49140MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
==================================================
Set CUDA_VISIBLE_DEVICES=0
Starting YARN + TTT training...
Context Extension: 4x (3000 -> 12000 tokens)
TTT Layers: 3 (layers 10, 20, 30)
Base Model: Frozen (only TTT params trained)
Warning: `hf_repo_id` is set but `config_path` is None. This will load default models.
2025-11-14 16:13:46 (IST) - 0:00:03 - distributed - INFO - torch.cuda.device_count: 1
2025-11-14 16:13:46 (IST) - 0:00:03 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0
2025-11-14 16:13:46 (IST) - 0:00:03 - distributed - INFO - local rank: 0
2025-11-14 16:13:46 (IST) - 0:00:03 - train - INFO - Going to init comms...
2025-11-14 16:13:46 (IST) - 0:00:03 - train - INFO - Run dir: /sise/eliyanac-group/ron_al/ttt_training_run2
2025-11-14 16:13:46 (IST) - 0:00:03 - train - INFO - Removing run dir /sise/eliyanac-group/ron_al/ttt_training_run2...
2025-11-14 16:13:47 (IST) - 0:00:04 - train - INFO - TrainArgs: {'batch_size': 2,
 'ckpt_freq': 100,
 'data': {'eval_data': '',
          'shuffle': False,
          'train_data': '/sise/eliyanac-group/ron_al/talkbank_callhome_english/talkbank.jsonl'},
 'do_ckpt': True,
 'do_eval': False,
 'duration_sec': 150.0,
 'eval_freq': 100,
 'first_codebook_weight_multiplier': 100.0,
 'full_finetuning': False,
 'gradient_checkpointing': True,
 'log_freq': 1,
 'lora': {'enable': False, 'ft_embed': False, 'rank': 64, 'scaling': 2.0},
 'max_norm': 1.0,
 'max_steps': 2000,
 'moshi_paths': {'config_path': None,
                 'hf_repo_id': 'kyutai/moshiko-pytorch-bf16',
                 'mimi_path': None,
                 'moshi_path': None,
                 'tokenizer_path': None},
 'num_ckpt_keep': 3,
 'num_microbatches': 1,
 'optim': {'lr': 0.001, 'pct_start': 0.05, 'weight_decay': 0.1},
 'overwrite_run_dir': True,
 'param_dtype': 'bfloat16',
 'run_dir': '/sise/eliyanac-group/ron_al/ttt_training_run2',
 'save_adapters': True,
 'seed': 0,
 'text_padding_weight': 0.5,
 'ttt': {'chunk_size': 256,
         'conv_kernel_size': 2,
         'delta_clip_fro_norm': 5.0,
         'enabled': True,
         'layer_frequency': 10,
         'learning_rate': 0.0001,
         'start_layer': 10,
         'unfreeze_ttt_layers': False},
 'wandb': {'key': '',
           'offline': False,
           'project': 'moshi_in_place',
           'run_name': 'run2'},
 'world_size': 1,
 'yarn': {'beta_fast': 32,
          'beta_slow': 1,
          'enabled': True,
          'mscale': 1.0,
          'mscale_all_dim': 0.0,
          'original_max_seq_len': 3000,
          'scale': 4.0}}
2025-11-14 16:13:47 (IST) - 0:00:04 - metrics_logger - INFO - initializing wandb
2025-11-14 16:13:49 (IST) - 0:00:06 - train - INFO - Loading Mimi and Moshi...
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - TTT (Test-Time Training) ENABLED
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Layer frequency: 10
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Start layer: 10
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Chunk size: 256
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Learning rate: 0.0001
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Conv kernel: 2
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - YaRN (Context Window Extension) ENABLED
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Scale: 4.0x
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Original max seq len: 3000
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Beta fast: 32
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   Beta slow: 1
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - ======================================================================
[YaRN] Enabled with scale=4.0, original_len=3000
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[TTT] Enabled TTT gating: chunk_size=256, lr=0.0001, dim=4096, hidden=11264
[YaRN] Initializing RoPE buffers on device=meta
[YaRN] RoPE buffers initialized successfully
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - Initializing TTT w_down from pretrained checkpoint...
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   ✓ transformer.layers.10.gating.w_down <- transformer.layers.10.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   ✓ transformer.layers.20.gating.w_down <- transformer.layers.20.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO -   ✓ transformer.layers.30.gating.w_down <- transformer.layers.30.gating.linear_out.weight (shape: torch.Size([4096, 11264]), dtype: float32)
2025-11-14 16:13:50 (IST) - 0:00:07 - finetune.wrapped_model - INFO - Initializing TTT layers ...
2025-11-14 16:13:51 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.10.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:51 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.10.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:51 (IST) - 0:00:08 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.10.gating.w_down_pretrained from w_down
2025-11-14 16:13:51 (IST) - 0:00:08 - finetune.wrapped_model - WARNING - Buffer transformer.layers.10.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:13:52 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.20.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:52 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.20.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:52 (IST) - 0:00:09 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.20.gating.w_down_pretrained from w_down
2025-11-14 16:13:52 (IST) - 0:00:09 - finetune.wrapped_model - WARNING - Buffer transformer.layers.20.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.30.gating.target_generator.conv1d.conv.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Small-random-initialized transformer.layers.30.gating.target_generator.W_target.weight (std=1e-4) for warm-start with gradient flow
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.layers.30.gating.w_down_pretrained from w_down
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - WARNING - Buffer transformer.layers.30.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - Initializing YaRN RoPE buffers ...
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO -   ✓ Initialized transformer.rope.inv_freq (shape: torch.Size([64]), scale: 4.0x)
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - Finished initialization!
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - TTT ACTIVE: 3 layers enabled
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - TTT layer indices: [10, 20, 30]
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - INFO - ======================================================================
2025-11-14 16:14:00 (IST) - 0:00:17 - train - INFO - [DocStream] step=1 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=0-1]
2025-11-14 16:14:00 (IST) - 0:00:17 - train - INFO - [TTT RESET] Document switch detected: None -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/0638.wav
2025-11-14 16:14:00 (IST) - 0:00:17 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:14:00 (IST) - 0:00:17 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:14:00 (IST) - 0:00:17 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000001
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   requires_grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   has grad: True
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO -   grad norm: 0.000001
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - =========================

2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - [TTT] Step 1: grad_norm=1.433e-06, param_norm=1.2215, delta_norm=5.450e-03, relative_change=0.4462% (6 params)
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - step: 000001 - done (%): 0.1 - loss: 3.378 - lr: 4.0e-05 - peak_alloc_mem (GB): 35.5 - alloc_mem (GB): 18.6 - words_per_second: 2927.2 - avg_words_per_second: 2927.2 - ETA: >2025-11-14 22:38:16
2025-11-14 16:14:08 (IST) - 0:00:25 - train - INFO - [DocStream] step=2 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=2-3]
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000001
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   requires_grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   has grad: True
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO -   grad norm: 0.000001
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - =========================

2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - [TTT] Step 2: grad_norm=1.156e-06, param_norm=1.2215, delta_norm=4.517e-03, relative_change=0.3698% (6 params)
2025-11-14 16:14:14 (IST) - 0:00:31 - train - INFO - step: 000002 - done (%): 0.1 - loss: 3.942 - lr: 4.0e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5592.3 - avg_words_per_second: 3842.9 - ETA: >2025-11-14 21:06:41
2025-11-14 16:14:15 (IST) - 0:00:32 - train - INFO - [DocStream] step=3 microbatch=0 samples=2 unique_docs=1 runs=0638.wav[segments=4-5]
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   requires_grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   has grad: True
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:20 (IST) - 0:00:38 - train - INFO - =========================

2025-11-14 16:14:21 (IST) - 0:00:38 - train - INFO - [TTT] Step 3: grad_norm=4.714e-07, param_norm=1.2216, delta_norm=3.380e-03, relative_change=0.2767% (6 params)
2025-11-14 16:14:21 (IST) - 0:00:38 - train - INFO - step: 000003 - done (%): 0.1 - loss: 3.365 - lr: 4.1e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5171.2 - avg_words_per_second: 4202.8 - ETA: >2025-11-14 20:41:37
2025-11-14 16:14:21 (IST) - 0:00:38 - train - INFO - [DocStream] step=4 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=0-1]
2025-11-14 16:14:21 (IST) - 0:00:38 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/0638.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4065.wav
2025-11-14 16:14:21 (IST) - 0:00:38 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:14:21 (IST) - 0:00:38 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:14:21 (IST) - 0:00:38 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - 
=== TTT Parameter Debug ===
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.10.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.10.gating.target_generator.W_target.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.20.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.20.gating.target_generator.W_target.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.30.gating.target_generator.conv1d.conv.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - transformer.layers.30.gating.target_generator.W_target.weight:
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   requires_grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   has grad: True
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO -   grad norm: 0.000000
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - =========================

2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - [TTT] Step 4: grad_norm=5.736e-07, param_norm=1.2216, delta_norm=2.813e-03, relative_change=0.2303% (6 params)
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - step: 000004 - done (%): 0.2 - loss: 4.810 - lr: 4.2e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5523.3 - avg_words_per_second: 4469.9 - ETA: >2025-11-14 20:25:37
2025-11-14 16:14:27 (IST) - 0:00:44 - train - INFO - [DocStream] step=5 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=2-3]
2025-11-14 16:14:33 (IST) - 0:00:50 - train - INFO - [TTT] Step 5: grad_norm=6.267e-07, param_norm=1.2216, delta_norm=2.556e-03, relative_change=0.2092% (6 params)
2025-11-14 16:14:33 (IST) - 0:00:50 - train - INFO - step: 000005 - done (%): 0.2 - loss: 4.950 - lr: 4.4e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5487.6 - avg_words_per_second: 4642.1 - ETA: >2025-11-14 20:16:17
2025-11-14 16:14:33 (IST) - 0:00:50 - train - INFO - [DocStream] step=6 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=4-5]
2025-11-14 16:14:39 (IST) - 0:00:56 - train - INFO - [TTT] Step 6: grad_norm=4.717e-07, param_norm=1.2216, delta_norm=2.330e-03, relative_change=0.1907% (6 params)
2025-11-14 16:14:39 (IST) - 0:00:56 - train - INFO - step: 000006 - done (%): 0.3 - loss: 3.375 - lr: 4.6e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5474.7 - avg_words_per_second: 4762.8 - ETA: >2025-11-14 20:10:09
2025-11-14 16:14:39 (IST) - 0:00:56 - train - INFO - [DocStream] step=7 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=6-7]
2025-11-14 16:14:45 (IST) - 0:01:02 - train - INFO - [TTT] Step 7: grad_norm=2.945e-07, param_norm=1.2216, delta_norm=2.113e-03, relative_change=0.1730% (6 params)
2025-11-14 16:14:45 (IST) - 0:01:02 - train - INFO - step: 000007 - done (%): 0.3 - loss: 2.610 - lr: 4.9e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5464.8 - avg_words_per_second: 4851.9 - ETA: >2025-11-14 20:05:49
2025-11-14 16:14:45 (IST) - 0:01:03 - train - INFO - [DocStream] step=8 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=8-9]
2025-11-14 16:14:51 (IST) - 0:01:08 - train - INFO - [TTT] Step 8: grad_norm=2.158e-07, param_norm=1.2217, delta_norm=1.951e-03, relative_change=0.1597% (6 params)
2025-11-14 16:14:51 (IST) - 0:01:08 - train - INFO - step: 000008 - done (%): 0.4 - loss: 2.319 - lr: 5.2e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5432.6 - avg_words_per_second: 4917.6 - ETA: >2025-11-14 20:02:43
2025-11-14 16:14:52 (IST) - 0:01:09 - train - INFO - [DocStream] step=9 microbatch=0 samples=2 unique_docs=1 runs=4065.wav[segments=10-11]
2025-11-14 16:14:58 (IST) - 0:01:15 - train - INFO - [TTT] Step 9: grad_norm=2.318e-07, param_norm=1.2217, delta_norm=1.828e-03, relative_change=0.1496% (6 params)
2025-11-14 16:14:58 (IST) - 0:01:15 - train - INFO - step: 000009 - done (%): 0.5 - loss: 2.321 - lr: 5.5e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5403.3 - avg_words_per_second: 4967.2 - ETA: >2025-11-14 20:00:26
2025-11-14 16:14:58 (IST) - 0:01:15 - train - INFO - [DocStream] step=10 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=0-1]
2025-11-14 16:14:58 (IST) - 0:01:15 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4065.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4074.wav
2025-11-14 16:14:58 (IST) - 0:01:15 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:14:58 (IST) - 0:01:15 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:14:58 (IST) - 0:01:15 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:15:04 (IST) - 0:01:21 - train - INFO - [TTT] Step 10: grad_norm=3.299e-07, param_norm=1.2217, delta_norm=1.756e-03, relative_change=0.1438% (6 params)
2025-11-14 16:15:04 (IST) - 0:01:21 - train - INFO - step: 000010 - done (%): 0.5 - loss: 5.038 - lr: 5.9e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5374.5 - avg_words_per_second: 5005.1 - ETA: >2025-11-14 19:58:43
2025-11-14 16:15:04 (IST) - 0:01:21 - train - INFO - [DocStream] step=11 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=2-3]
2025-11-14 16:15:10 (IST) - 0:01:27 - train - INFO - [TTT] Step 11: grad_norm=2.925e-07, param_norm=1.2217, delta_norm=1.715e-03, relative_change=0.1404% (6 params)
2025-11-14 16:15:10 (IST) - 0:01:27 - train - INFO - step: 000011 - done (%): 0.6 - loss: 4.584 - lr: 6.4e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5359.3 - avg_words_per_second: 5035.4 - ETA: >2025-11-14 19:57:22
2025-11-14 16:15:10 (IST) - 0:01:28 - train - INFO - [DocStream] step=12 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=4-5]
2025-11-14 16:15:16 (IST) - 0:01:34 - train - INFO - [TTT] Step 12: grad_norm=2.196e-07, param_norm=1.2217, delta_norm=1.685e-03, relative_change=0.1380% (6 params)
2025-11-14 16:15:16 (IST) - 0:01:34 - train - INFO - step: 000012 - done (%): 0.6 - loss: 2.718 - lr: 6.9e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5326.5 - avg_words_per_second: 5058.4 - ETA: >2025-11-14 19:56:20
2025-11-14 16:15:17 (IST) - 0:01:34 - train - INFO - [DocStream] step=13 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=6-7]
2025-11-14 16:15:23 (IST) - 0:01:40 - train - INFO - [TTT] Step 13: grad_norm=4.016e-07, param_norm=1.2218, delta_norm=1.712e-03, relative_change=0.1401% (6 params)
2025-11-14 16:15:23 (IST) - 0:01:40 - train - INFO - step: 000013 - done (%): 0.7 - loss: 3.064 - lr: 7.4e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5308.8 - avg_words_per_second: 5076.8 - ETA: >2025-11-14 19:55:32
2025-11-14 16:15:23 (IST) - 0:01:40 - train - INFO - [DocStream] step=14 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=8-9]
2025-11-14 16:15:29 (IST) - 0:01:46 - train - INFO - [TTT] Step 14: grad_norm=4.086e-07, param_norm=1.2218, delta_norm=1.790e-03, relative_change=0.1465% (6 params)
2025-11-14 16:15:29 (IST) - 0:01:46 - train - INFO - step: 000014 - done (%): 0.7 - loss: 2.885 - lr: 8.0e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5284.5 - avg_words_per_second: 5091.1 - ETA: >2025-11-14 19:54:55
2025-11-14 16:15:30 (IST) - 0:01:47 - train - INFO - [DocStream] step=15 microbatch=0 samples=2 unique_docs=1 runs=4074.wav[segments=10-11]
2025-11-14 16:15:36 (IST) - 0:01:53 - train - INFO - [TTT] Step 15: grad_norm=1.930e-07, param_norm=1.2218, delta_norm=1.814e-03, relative_change=0.1484% (6 params)
2025-11-14 16:15:36 (IST) - 0:01:53 - train - INFO - step: 000015 - done (%): 0.8 - loss: 2.802 - lr: 8.7e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5286.2 - avg_words_per_second: 5103.7 - ETA: >2025-11-14 19:54:22
2025-11-14 16:15:36 (IST) - 0:01:53 - train - INFO - [DocStream] step=16 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=0-1]
2025-11-14 16:15:36 (IST) - 0:01:53 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4074.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4077.wav
2025-11-14 16:15:36 (IST) - 0:01:53 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:15:36 (IST) - 0:01:53 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:15:36 (IST) - 0:01:53 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:15:42 (IST) - 0:01:59 - train - INFO - [TTT] Step 16: grad_norm=1.123e-06, param_norm=1.2218, delta_norm=1.754e-03, relative_change=0.1435% (6 params)
2025-11-14 16:15:42 (IST) - 0:01:59 - train - INFO - step: 000016 - done (%): 0.8 - loss: 4.239 - lr: 9.3e-05 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5247.7 - avg_words_per_second: 5112.5 - ETA: >2025-11-14 19:53:59
2025-11-14 16:15:42 (IST) - 0:02:00 - train - INFO - [DocStream] step=17 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=2-3]
2025-11-14 16:15:48 (IST) - 0:02:06 - train - INFO - [TTT] Step 17: grad_norm=1.155e-06, param_norm=1.2219, delta_norm=2.192e-03, relative_change=0.1794% (6 params)
2025-11-14 16:15:48 (IST) - 0:02:06 - train - INFO - step: 000017 - done (%): 0.8 - loss: 4.053 - lr: 1.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5252.1 - avg_words_per_second: 5120.5 - ETA: >2025-11-14 19:53:39
2025-11-14 16:15:49 (IST) - 0:02:06 - train - INFO - [DocStream] step=18 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=4-5]
2025-11-14 16:15:55 (IST) - 0:02:12 - train - INFO - [TTT] Step 18: grad_norm=2.063e-07, param_norm=1.2219, delta_norm=2.154e-03, relative_change=0.1763% (6 params)
2025-11-14 16:15:55 (IST) - 0:02:12 - train - INFO - step: 000018 - done (%): 0.9 - loss: 2.535 - lr: 1.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5247.9 - avg_words_per_second: 5127.4 - ETA: >2025-11-14 19:53:21
2025-11-14 16:15:55 (IST) - 0:02:12 - train - INFO - [DocStream] step=19 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=6-7]
2025-11-14 16:16:01 (IST) - 0:02:18 - train - INFO - [TTT] Step 19: grad_norm=3.101e-07, param_norm=1.2219, delta_norm=2.117e-03, relative_change=0.1733% (6 params)
2025-11-14 16:16:01 (IST) - 0:02:19 - train - INFO - step: 000019 - done (%): 0.9 - loss: 3.870 - lr: 1.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5232.6 - avg_words_per_second: 5132.8 - ETA: >2025-11-14 19:53:07
2025-11-14 16:16:02 (IST) - 0:02:19 - train - INFO - [DocStream] step=20 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=8-9]
2025-11-14 16:16:08 (IST) - 0:02:25 - train - INFO - [TTT] Step 20: grad_norm=2.380e-07, param_norm=1.2219, delta_norm=2.119e-03, relative_change=0.1734% (6 params)
2025-11-14 16:16:08 (IST) - 0:02:25 - train - INFO - step: 000020 - done (%): 1.0 - loss: 3.452 - lr: 1.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5232.6 - avg_words_per_second: 5137.7 - ETA: >2025-11-14 19:52:55
2025-11-14 16:16:08 (IST) - 0:02:25 - train - INFO - [DocStream] step=21 microbatch=0 samples=2 unique_docs=1 runs=4077.wav[segments=10-11]
2025-11-14 16:16:14 (IST) - 0:02:31 - train - INFO - [TTT] Step 21: grad_norm=1.431e-07, param_norm=1.2220, delta_norm=2.102e-03, relative_change=0.1720% (6 params)
2025-11-14 16:16:14 (IST) - 0:02:31 - train - INFO - step: 000021 - done (%): 1.1 - loss: 1.979 - lr: 1.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5221.9 - avg_words_per_second: 5141.7 - ETA: >2025-11-14 19:52:44
2025-11-14 16:16:15 (IST) - 0:02:32 - train - INFO - [DocStream] step=22 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=0-1]
2025-11-14 16:16:15 (IST) - 0:02:32 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4077.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4092.wav
2025-11-14 16:16:15 (IST) - 0:02:32 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:16:15 (IST) - 0:02:32 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:16:15 (IST) - 0:02:32 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:16:21 (IST) - 0:02:38 - train - INFO - [TTT] Step 22: grad_norm=3.090e-07, param_norm=1.2220, delta_norm=2.024e-03, relative_change=0.1656% (6 params)
2025-11-14 16:16:21 (IST) - 0:02:38 - train - INFO - step: 000022 - done (%): 1.1 - loss: 3.864 - lr: 1.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5200.4 - avg_words_per_second: 5144.3 - ETA: >2025-11-14 19:52:38
2025-11-14 16:16:21 (IST) - 0:02:38 - train - INFO - [DocStream] step=23 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=2-3]
2025-11-14 16:16:27 (IST) - 0:02:44 - train - INFO - [TTT] Step 23: grad_norm=2.546e-07, param_norm=1.2220, delta_norm=1.967e-03, relative_change=0.1610% (6 params)
2025-11-14 16:16:27 (IST) - 0:02:44 - train - INFO - step: 000023 - done (%): 1.1 - loss: 3.770 - lr: 1.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5186.8 - avg_words_per_second: 5146.1 - ETA: >2025-11-14 19:52:33
2025-11-14 16:16:28 (IST) - 0:02:45 - train - INFO - [DocStream] step=24 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=4-5]
2025-11-14 16:16:34 (IST) - 0:02:51 - train - INFO - [TTT] Step 24: grad_norm=1.347e-07, param_norm=1.2221, delta_norm=1.921e-03, relative_change=0.1572% (6 params)
2025-11-14 16:16:34 (IST) - 0:02:51 - train - INFO - step: 000024 - done (%): 1.2 - loss: 2.563 - lr: 1.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5195.4 - avg_words_per_second: 5148.2 - ETA: >2025-11-14 19:52:28
2025-11-14 16:16:34 (IST) - 0:02:51 - train - INFO - [DocStream] step=25 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=6-7]
2025-11-14 16:16:40 (IST) - 0:02:57 - train - INFO - [TTT] Step 25: grad_norm=1.288e-07, param_norm=1.2221, delta_norm=1.897e-03, relative_change=0.1552% (6 params)
2025-11-14 16:16:40 (IST) - 0:02:57 - train - INFO - step: 000025 - done (%): 1.2 - loss: 2.588 - lr: 1.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5188.5 - avg_words_per_second: 5149.8 - ETA: >2025-11-14 19:52:24
2025-11-14 16:16:41 (IST) - 0:02:58 - train - INFO - [DocStream] step=26 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=8-9]
2025-11-14 16:16:47 (IST) - 0:03:04 - train - INFO - [TTT] Step 26: grad_norm=1.222e-07, param_norm=1.2222, delta_norm=1.869e-03, relative_change=0.1529% (6 params)
2025-11-14 16:16:47 (IST) - 0:03:04 - train - INFO - step: 000026 - done (%): 1.3 - loss: 1.815 - lr: 1.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5176.9 - avg_words_per_second: 5150.8 - ETA: >2025-11-14 19:52:21
2025-11-14 16:16:47 (IST) - 0:03:04 - train - INFO - [DocStream] step=27 microbatch=0 samples=2 unique_docs=1 runs=4092.wav[segments=10-11]
2025-11-14 16:16:53 (IST) - 0:03:11 - train - INFO - [TTT] Step 27: grad_norm=1.139e-07, param_norm=1.2222, delta_norm=1.848e-03, relative_change=0.1512% (6 params)
2025-11-14 16:16:53 (IST) - 0:03:11 - train - INFO - step: 000027 - done (%): 1.4 - loss: 2.477 - lr: 1.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5147.7 - avg_words_per_second: 5150.7 - ETA: >2025-11-14 19:52:21
2025-11-14 16:16:54 (IST) - 0:03:11 - train - INFO - [DocStream] step=28 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=0-1]
2025-11-14 16:16:54 (IST) - 0:03:11 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4092.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4104.wav
2025-11-14 16:16:54 (IST) - 0:03:11 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:16:54 (IST) - 0:03:11 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:16:54 (IST) - 0:03:11 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:17:00 (IST) - 0:03:17 - train - INFO - [TTT] Step 28: grad_norm=2.040e-07, param_norm=1.2222, delta_norm=1.788e-03, relative_change=0.1463% (6 params)
2025-11-14 16:17:00 (IST) - 0:03:17 - train - INFO - step: 000028 - done (%): 1.4 - loss: 3.958 - lr: 2.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5150.0 - avg_words_per_second: 5150.7 - ETA: >2025-11-14 19:52:22
2025-11-14 16:17:00 (IST) - 0:03:17 - train - INFO - [DocStream] step=29 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=2-3]
2025-11-14 16:17:07 (IST) - 0:03:24 - train - INFO - [TTT] Step 29: grad_norm=1.718e-07, param_norm=1.2223, delta_norm=1.757e-03, relative_change=0.1437% (6 params)
2025-11-14 16:17:07 (IST) - 0:03:24 - train - INFO - step: 000029 - done (%): 1.4 - loss: 3.995 - lr: 2.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5100.3 - avg_words_per_second: 5148.9 - ETA: >2025-11-14 19:52:26
2025-11-14 16:17:07 (IST) - 0:03:24 - train - INFO - [DocStream] step=30 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=4-5]
2025-11-14 16:17:13 (IST) - 0:03:30 - train - INFO - [TTT] Step 30: grad_norm=9.366e-08, param_norm=1.2223, delta_norm=1.738e-03, relative_change=0.1422% (6 params)
2025-11-14 16:17:13 (IST) - 0:03:30 - train - INFO - step: 000030 - done (%): 1.5 - loss: 1.973 - lr: 2.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5147.6 - avg_words_per_second: 5148.9 - ETA: >2025-11-14 19:52:26
2025-11-14 16:17:13 (IST) - 0:03:31 - train - INFO - [DocStream] step=31 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=6-7]
2025-11-14 16:17:20 (IST) - 0:03:37 - train - INFO - [TTT] Step 31: grad_norm=9.140e-08, param_norm=1.2223, delta_norm=1.725e-03, relative_change=0.1411% (6 params)
2025-11-14 16:17:20 (IST) - 0:03:37 - train - INFO - step: 000031 - done (%): 1.6 - loss: 2.289 - lr: 2.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5149.5 - avg_words_per_second: 5148.9 - ETA: >2025-11-14 19:52:26
2025-11-14 16:17:20 (IST) - 0:03:37 - train - INFO - [DocStream] step=32 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=8-9]
2025-11-14 16:17:26 (IST) - 0:03:43 - train - INFO - [TTT] Step 32: grad_norm=1.050e-07, param_norm=1.2223, delta_norm=1.722e-03, relative_change=0.1409% (6 params)
2025-11-14 16:17:26 (IST) - 0:03:43 - train - INFO - step: 000032 - done (%): 1.6 - loss: 2.075 - lr: 2.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5147.8 - avg_words_per_second: 5148.9 - ETA: >2025-11-14 19:52:26
2025-11-14 16:17:27 (IST) - 0:03:44 - train - INFO - [DocStream] step=33 microbatch=0 samples=2 unique_docs=1 runs=4104.wav[segments=10-11]
2025-11-14 16:17:33 (IST) - 0:03:50 - train - INFO - [TTT] Step 33: grad_norm=7.572e-08, param_norm=1.2224, delta_norm=1.723e-03, relative_change=0.1409% (6 params)
2025-11-14 16:17:33 (IST) - 0:03:50 - train - INFO - step: 000033 - done (%): 1.6 - loss: 1.945 - lr: 2.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5132.3 - avg_words_per_second: 5148.4 - ETA: >2025-11-14 19:52:27
2025-11-14 16:17:33 (IST) - 0:03:50 - train - INFO - [DocStream] step=34 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=0-1]
2025-11-14 16:17:33 (IST) - 0:03:50 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4104.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4112.wav
2025-11-14 16:17:33 (IST) - 0:03:50 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:17:33 (IST) - 0:03:50 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:17:33 (IST) - 0:03:50 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:17:39 (IST) - 0:03:57 - train - INFO - [TTT] Step 34: grad_norm=2.333e-07, param_norm=1.2224, delta_norm=1.617e-03, relative_change=0.1323% (6 params)
2025-11-14 16:17:39 (IST) - 0:03:57 - train - INFO - step: 000034 - done (%): 1.7 - loss: 4.182 - lr: 2.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5132.9 - avg_words_per_second: 5147.9 - ETA: >2025-11-14 19:52:29
2025-11-14 16:17:40 (IST) - 0:03:57 - train - INFO - [DocStream] step=35 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=2-3]
2025-11-14 16:17:46 (IST) - 0:04:03 - train - INFO - [TTT] Step 35: grad_norm=8.625e-08, param_norm=1.2224, delta_norm=1.558e-03, relative_change=0.1274% (6 params)
2025-11-14 16:17:46 (IST) - 0:04:03 - train - INFO - step: 000035 - done (%): 1.8 - loss: 3.400 - lr: 2.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5132.3 - avg_words_per_second: 5147.5 - ETA: >2025-11-14 19:52:30
2025-11-14 16:17:46 (IST) - 0:04:03 - train - INFO - [DocStream] step=36 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=4-5]
2025-11-14 16:17:53 (IST) - 0:04:10 - train - INFO - [TTT] Step 36: grad_norm=1.228e-07, param_norm=1.2224, delta_norm=1.541e-03, relative_change=0.1260% (6 params)
2025-11-14 16:17:53 (IST) - 0:04:10 - train - INFO - step: 000036 - done (%): 1.8 - loss: 2.910 - lr: 3.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5136.6 - avg_words_per_second: 5147.1 - ETA: >2025-11-14 19:52:31
2025-11-14 16:17:53 (IST) - 0:04:10 - train - INFO - [DocStream] step=37 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=6-7]
2025-11-14 16:17:59 (IST) - 0:04:16 - train - INFO - [TTT] Step 37: grad_norm=1.013e-07, param_norm=1.2225, delta_norm=1.551e-03, relative_change=0.1269% (6 params)
2025-11-14 16:17:59 (IST) - 0:04:16 - train - INFO - step: 000037 - done (%): 1.9 - loss: 2.659 - lr: 3.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5133.7 - avg_words_per_second: 5146.8 - ETA: >2025-11-14 19:52:31
2025-11-14 16:17:59 (IST) - 0:04:17 - train - INFO - [DocStream] step=38 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=8-9]
2025-11-14 16:18:06 (IST) - 0:04:23 - train - INFO - [TTT] Step 38: grad_norm=7.868e-08, param_norm=1.2225, delta_norm=1.555e-03, relative_change=0.1272% (6 params)
2025-11-14 16:18:06 (IST) - 0:04:23 - train - INFO - step: 000038 - done (%): 1.9 - loss: 2.412 - lr: 3.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5132.0 - avg_words_per_second: 5146.4 - ETA: >2025-11-14 19:52:32
2025-11-14 16:18:06 (IST) - 0:04:23 - train - INFO - [DocStream] step=39 microbatch=0 samples=2 unique_docs=1 runs=4112.wav[segments=10-11]
2025-11-14 16:18:12 (IST) - 0:04:29 - train - INFO - [TTT] Step 39: grad_norm=7.465e-08, param_norm=1.2225, delta_norm=1.580e-03, relative_change=0.1293% (6 params)
2025-11-14 16:18:12 (IST) - 0:04:29 - train - INFO - step: 000039 - done (%): 1.9 - loss: 2.046 - lr: 3.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5136.9 - avg_words_per_second: 5146.1 - ETA: >2025-11-14 19:52:33
2025-11-14 16:18:13 (IST) - 0:04:30 - train - INFO - [DocStream] step=40 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=0-1]
2025-11-14 16:18:13 (IST) - 0:04:30 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4112.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4145.wav
2025-11-14 16:18:13 (IST) - 0:04:30 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:18:13 (IST) - 0:04:30 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:18:13 (IST) - 0:04:30 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:18:19 (IST) - 0:04:36 - train - INFO - [TTT] Step 40: grad_norm=1.800e-07, param_norm=1.2225, delta_norm=1.473e-03, relative_change=0.1205% (6 params)
2025-11-14 16:18:19 (IST) - 0:04:36 - train - INFO - step: 000040 - done (%): 2.0 - loss: 4.981 - lr: 3.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.7 - avg_words_per_second: 5145.4 - ETA: >2025-11-14 19:52:35
2025-11-14 16:18:19 (IST) - 0:04:36 - train - INFO - [DocStream] step=41 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=2-3]
2025-11-14 16:18:25 (IST) - 0:04:43 - train - INFO - [TTT] Step 41: grad_norm=4.113e-07, param_norm=1.2225, delta_norm=1.700e-03, relative_change=0.1390% (6 params)
2025-11-14 16:18:25 (IST) - 0:04:43 - train - INFO - step: 000041 - done (%): 2.0 - loss: 3.974 - lr: 3.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5130.9 - avg_words_per_second: 5145.1 - ETA: >2025-11-14 19:52:36
2025-11-14 16:18:26 (IST) - 0:04:43 - train - INFO - [DocStream] step=42 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=4-5]
2025-11-14 16:18:32 (IST) - 0:04:49 - train - INFO - [TTT] Step 42: grad_norm=8.989e-08, param_norm=1.2225, delta_norm=1.677e-03, relative_change=0.1372% (6 params)
2025-11-14 16:18:32 (IST) - 0:04:49 - train - INFO - step: 000042 - done (%): 2.1 - loss: 3.740 - lr: 3.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.5 - avg_words_per_second: 5144.4 - ETA: >2025-11-14 19:52:38
2025-11-14 16:18:32 (IST) - 0:04:50 - train - INFO - [DocStream] step=43 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=6-7]
2025-11-14 16:18:39 (IST) - 0:04:56 - train - INFO - [TTT] Step 43: grad_norm=1.005e-07, param_norm=1.2225, delta_norm=1.696e-03, relative_change=0.1387% (6 params)
2025-11-14 16:18:39 (IST) - 0:04:56 - train - INFO - step: 000043 - done (%): 2.1 - loss: 1.905 - lr: 4.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5070.1 - avg_words_per_second: 5142.6 - ETA: >2025-11-14 19:52:42
2025-11-14 16:18:39 (IST) - 0:04:56 - train - INFO - [DocStream] step=44 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=8-9]
2025-11-14 16:18:45 (IST) - 0:05:02 - train - INFO - [TTT] Step 44: grad_norm=1.006e-07, param_norm=1.2225, delta_norm=1.716e-03, relative_change=0.1404% (6 params)
2025-11-14 16:18:45 (IST) - 0:05:02 - train - INFO - step: 000044 - done (%): 2.2 - loss: 2.634 - lr: 4.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5131.9 - avg_words_per_second: 5142.4 - ETA: >2025-11-14 19:52:43
2025-11-14 16:18:46 (IST) - 0:05:03 - train - INFO - [DocStream] step=45 microbatch=0 samples=2 unique_docs=1 runs=4145.wav[segments=10-11]
2025-11-14 16:18:52 (IST) - 0:05:09 - train - INFO - [TTT] Step 45: grad_norm=9.195e-08, param_norm=1.2225, delta_norm=1.803e-03, relative_change=0.1475% (6 params)
2025-11-14 16:18:52 (IST) - 0:05:09 - train - INFO - step: 000045 - done (%): 2.2 - loss: 2.330 - lr: 4.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.0 - avg_words_per_second: 5141.8 - ETA: >2025-11-14 19:52:44
2025-11-14 16:18:52 (IST) - 0:05:09 - train - INFO - [DocStream] step=46 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=0-1]
2025-11-14 16:18:52 (IST) - 0:05:09 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4145.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4156.wav
2025-11-14 16:18:52 (IST) - 0:05:09 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:18:52 (IST) - 0:05:09 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:18:52 (IST) - 0:05:09 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:18:58 (IST) - 0:05:16 - train - INFO - [TTT] Step 46: grad_norm=2.571e-07, param_norm=1.2225, delta_norm=2.061e-03, relative_change=0.1686% (6 params)
2025-11-14 16:18:58 (IST) - 0:05:16 - train - INFO - step: 000046 - done (%): 2.3 - loss: 4.402 - lr: 4.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.6 - avg_words_per_second: 5141.3 - ETA: >2025-11-14 19:52:45
2025-11-14 16:18:59 (IST) - 0:05:16 - train - INFO - [DocStream] step=47 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=2-3]
2025-11-14 16:19:05 (IST) - 0:05:22 - train - INFO - [TTT] Step 47: grad_norm=1.916e-07, param_norm=1.2225, delta_norm=2.450e-03, relative_change=0.2004% (6 params)
2025-11-14 16:19:05 (IST) - 0:05:22 - train - INFO - step: 000047 - done (%): 2.4 - loss: 4.791 - lr: 4.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.4 - avg_words_per_second: 5140.8 - ETA: >2025-11-14 19:52:47
2025-11-14 16:19:05 (IST) - 0:05:23 - train - INFO - [DocStream] step=48 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=4-5]
2025-11-14 16:19:12 (IST) - 0:05:29 - train - INFO - [TTT] Step 48: grad_norm=2.547e-07, param_norm=1.2225, delta_norm=3.121e-03, relative_change=0.2553% (6 params)
2025-11-14 16:19:12 (IST) - 0:05:29 - train - INFO - step: 000048 - done (%): 2.4 - loss: 4.998 - lr: 4.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5134.4 - avg_words_per_second: 5140.6 - ETA: >2025-11-14 19:52:47
2025-11-14 16:19:12 (IST) - 0:05:29 - train - INFO - [DocStream] step=49 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=6-7]
2025-11-14 16:19:18 (IST) - 0:05:35 - train - INFO - [TTT] Step 49: grad_norm=1.746e-07, param_norm=1.2225, delta_norm=3.478e-03, relative_change=0.2845% (6 params)
2025-11-14 16:19:18 (IST) - 0:05:35 - train - INFO - step: 000049 - done (%): 2.5 - loss: 5.164 - lr: 5.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5115.9 - avg_words_per_second: 5140.1 - ETA: >2025-11-14 19:52:48
2025-11-14 16:19:19 (IST) - 0:05:36 - train - INFO - [DocStream] step=50 microbatch=0 samples=2 unique_docs=1 runs=4156.wav[segments=8-9]
2025-11-14 16:19:25 (IST) - 0:05:42 - train - INFO - [TTT] Step 50: grad_norm=5.537e-07, param_norm=1.2225, delta_norm=4.648e-03, relative_change=0.3802% (6 params)
2025-11-14 16:19:25 (IST) - 0:05:42 - train - INFO - step: 000050 - done (%): 2.5 - loss: 4.784 - lr: 5.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5211.5 - avg_words_per_second: 5141.5 - ETA: >2025-11-14 19:52:45
2025-11-14 16:19:25 (IST) - 0:05:42 - train - INFO - [DocStream] step=51 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=0-1]
2025-11-14 16:19:25 (IST) - 0:05:42 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4156.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4157.wav
2025-11-14 16:19:25 (IST) - 0:05:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:19:25 (IST) - 0:05:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:19:25 (IST) - 0:05:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:19:31 (IST) - 0:05:48 - train - INFO - [TTT] Step 51: grad_norm=1.143e-07, param_norm=1.2225, delta_norm=4.483e-03, relative_change=0.3667% (6 params)
2025-11-14 16:19:31 (IST) - 0:05:48 - train - INFO - step: 000051 - done (%): 2.5 - loss: 4.900 - lr: 5.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5101.8 - avg_words_per_second: 5140.8 - ETA: >2025-11-14 19:52:47
2025-11-14 16:19:32 (IST) - 0:05:49 - train - INFO - [DocStream] step=52 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=2-3]
2025-11-14 16:19:38 (IST) - 0:05:55 - train - INFO - [TTT] Step 52: grad_norm=1.106e-07, param_norm=1.2226, delta_norm=4.237e-03, relative_change=0.3466% (6 params)
2025-11-14 16:19:38 (IST) - 0:05:55 - train - INFO - step: 000052 - done (%): 2.6 - loss: 4.385 - lr: 5.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5115.2 - avg_words_per_second: 5140.3 - ETA: >2025-11-14 19:52:48
2025-11-14 16:19:38 (IST) - 0:05:55 - train - INFO - [DocStream] step=53 microbatch=0 samples=2 unique_docs=1 runs=4157.wav[segments=4-5]
2025-11-14 16:19:44 (IST) - 0:06:02 - train - INFO - [TTT] Step 53: grad_norm=8.012e-08, param_norm=1.2226, delta_norm=3.756e-03, relative_change=0.3072% (6 params)
2025-11-14 16:19:44 (IST) - 0:06:02 - train - INFO - step: 000053 - done (%): 2.6 - loss: 3.942 - lr: 5.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5237.7 - avg_words_per_second: 5142.1 - ETA: >2025-11-14 19:52:44
2025-11-14 16:19:45 (IST) - 0:06:02 - train - INFO - [DocStream] step=54 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=0-1]
2025-11-14 16:19:45 (IST) - 0:06:02 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4157.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4170.wav
2025-11-14 16:19:45 (IST) - 0:06:02 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:19:45 (IST) - 0:06:02 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:19:45 (IST) - 0:06:02 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:19:51 (IST) - 0:06:08 - train - INFO - [TTT] Step 54: grad_norm=1.547e-07, param_norm=1.2226, delta_norm=3.377e-03, relative_change=0.2762% (6 params)
2025-11-14 16:19:51 (IST) - 0:06:08 - train - INFO - step: 000054 - done (%): 2.7 - loss: 4.465 - lr: 5.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5108.5 - avg_words_per_second: 5141.4 - ETA: >2025-11-14 19:52:45
2025-11-14 16:19:51 (IST) - 0:06:08 - train - INFO - [DocStream] step=55 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=2-3]
2025-11-14 16:19:58 (IST) - 0:06:15 - train - INFO - [TTT] Step 55: grad_norm=1.603e-07, param_norm=1.2226, delta_norm=3.213e-03, relative_change=0.2628% (6 params)
2025-11-14 16:19:58 (IST) - 0:06:15 - train - INFO - step: 000055 - done (%): 2.8 - loss: 4.874 - lr: 5.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.0 - avg_words_per_second: 5141.0 - ETA: >2025-11-14 19:52:46
2025-11-14 16:19:58 (IST) - 0:06:15 - train - INFO - [DocStream] step=56 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=4-5]
2025-11-14 16:20:04 (IST) - 0:06:21 - train - INFO - [TTT] Step 56: grad_norm=1.399e-07, param_norm=1.2227, delta_norm=3.148e-03, relative_change=0.2575% (6 params)
2025-11-14 16:20:04 (IST) - 0:06:21 - train - INFO - step: 000056 - done (%): 2.8 - loss: 5.385 - lr: 6.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.3 - avg_words_per_second: 5140.6 - ETA: >2025-11-14 19:52:47
2025-11-14 16:20:05 (IST) - 0:06:22 - train - INFO - [DocStream] step=57 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=6-7]
2025-11-14 16:20:11 (IST) - 0:06:28 - train - INFO - [TTT] Step 57: grad_norm=1.635e-07, param_norm=1.2227, delta_norm=3.484e-03, relative_change=0.2849% (6 params)
2025-11-14 16:20:11 (IST) - 0:06:28 - train - INFO - step: 000057 - done (%): 2.9 - loss: 5.059 - lr: 6.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5087.8 - avg_words_per_second: 5139.6 - ETA: >2025-11-14 19:52:50
2025-11-14 16:20:11 (IST) - 0:06:28 - train - INFO - [DocStream] step=58 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=8-9]
2025-11-14 16:20:17 (IST) - 0:06:35 - train - INFO - [TTT] Step 58: grad_norm=1.719e-07, param_norm=1.2227, delta_norm=3.921e-03, relative_change=0.3207% (6 params)
2025-11-14 16:20:17 (IST) - 0:06:35 - train - INFO - step: 000058 - done (%): 2.9 - loss: 4.863 - lr: 6.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5100.5 - avg_words_per_second: 5138.9 - ETA: >2025-11-14 19:52:52
2025-11-14 16:20:18 (IST) - 0:06:35 - train - INFO - [DocStream] step=59 microbatch=0 samples=2 unique_docs=1 runs=4170.wav[segments=10-11]
2025-11-14 16:20:24 (IST) - 0:06:41 - train - INFO - [TTT] Step 59: grad_norm=1.329e-07, param_norm=1.2227, delta_norm=4.212e-03, relative_change=0.3445% (6 params)
2025-11-14 16:20:24 (IST) - 0:06:41 - train - INFO - step: 000059 - done (%): 3.0 - loss: 4.906 - lr: 6.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.5 - avg_words_per_second: 5138.6 - ETA: >2025-11-14 19:52:53
2025-11-14 16:20:24 (IST) - 0:06:42 - train - INFO - [DocStream] step=60 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=0-1]
2025-11-14 16:20:24 (IST) - 0:06:42 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4170.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4183.wav
2025-11-14 16:20:24 (IST) - 0:06:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:20:24 (IST) - 0:06:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:20:24 (IST) - 0:06:42 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:20:31 (IST) - 0:06:48 - train - INFO - [TTT] Step 60: grad_norm=3.747e-07, param_norm=1.2228, delta_norm=5.521e-03, relative_change=0.4515% (6 params)
2025-11-14 16:20:31 (IST) - 0:06:48 - train - INFO - step: 000060 - done (%): 3.0 - loss: 4.430 - lr: 6.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5118.1 - avg_words_per_second: 5138.2 - ETA: >2025-11-14 19:52:53
2025-11-14 16:20:31 (IST) - 0:06:48 - train - INFO - [DocStream] step=61 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=2-3]
2025-11-14 16:20:37 (IST) - 0:06:54 - train - INFO - [TTT] Step 61: grad_norm=1.885e-07, param_norm=1.2228, delta_norm=5.646e-03, relative_change=0.4617% (6 params)
2025-11-14 16:20:37 (IST) - 0:06:54 - train - INFO - step: 000061 - done (%): 3.0 - loss: 4.377 - lr: 6.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.7 - avg_words_per_second: 5137.9 - ETA: >2025-11-14 19:52:54
2025-11-14 16:20:38 (IST) - 0:06:55 - train - INFO - [DocStream] step=62 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=4-5]
2025-11-14 16:20:44 (IST) - 0:07:01 - train - INFO - [TTT] Step 62: grad_norm=1.778e-07, param_norm=1.2229, delta_norm=5.963e-03, relative_change=0.4876% (6 params)
2025-11-14 16:20:44 (IST) - 0:07:01 - train - INFO - step: 000062 - done (%): 3.1 - loss: 4.349 - lr: 6.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5118.3 - avg_words_per_second: 5137.5 - ETA: >2025-11-14 19:52:55
2025-11-14 16:20:44 (IST) - 0:07:01 - train - INFO - [DocStream] step=63 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=6-7]
2025-11-14 16:20:50 (IST) - 0:07:08 - train - INFO - [TTT] Step 63: grad_norm=1.918e-07, param_norm=1.2229, delta_norm=6.388e-03, relative_change=0.5224% (6 params)
2025-11-14 16:20:50 (IST) - 0:07:08 - train - INFO - step: 000063 - done (%): 3.1 - loss: 4.373 - lr: 7.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.8 - avg_words_per_second: 5137.2 - ETA: >2025-11-14 19:52:56
2025-11-14 16:20:51 (IST) - 0:07:08 - train - INFO - [DocStream] step=64 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=8-9]
2025-11-14 16:20:57 (IST) - 0:07:14 - train - INFO - [TTT] Step 64: grad_norm=1.618e-07, param_norm=1.2230, delta_norm=6.684e-03, relative_change=0.5465% (6 params)
2025-11-14 16:20:57 (IST) - 0:07:14 - train - INFO - step: 000064 - done (%): 3.2 - loss: 4.178 - lr: 7.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.6 - avg_words_per_second: 5136.9 - ETA: >2025-11-14 19:52:57
2025-11-14 16:20:57 (IST) - 0:07:15 - train - INFO - [DocStream] step=65 microbatch=0 samples=2 unique_docs=1 runs=4183.wav[segments=10-11]
2025-11-14 16:21:04 (IST) - 0:07:21 - train - INFO - [TTT] Step 65: grad_norm=1.219e-07, param_norm=1.2231, delta_norm=6.647e-03, relative_change=0.5435% (6 params)
2025-11-14 16:21:04 (IST) - 0:07:21 - train - INFO - step: 000065 - done (%): 3.2 - loss: 4.326 - lr: 7.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5133.5 - avg_words_per_second: 5136.9 - ETA: >2025-11-14 19:52:57
2025-11-14 16:21:04 (IST) - 0:07:21 - train - INFO - [DocStream] step=66 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=0-1]
2025-11-14 16:21:04 (IST) - 0:07:21 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4183.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4184.wav
2025-11-14 16:21:04 (IST) - 0:07:21 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:21:04 (IST) - 0:07:21 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:21:04 (IST) - 0:07:21 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:21:10 (IST) - 0:07:27 - train - INFO - [TTT] Step 66: grad_norm=8.328e-08, param_norm=1.2232, delta_norm=5.596e-03, relative_change=0.4575% (6 params)
2025-11-14 16:21:10 (IST) - 0:07:27 - train - INFO - step: 000066 - done (%): 3.3 - loss: 4.735 - lr: 7.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5114.8 - avg_words_per_second: 5136.5 - ETA: >2025-11-14 19:52:58
2025-11-14 16:21:11 (IST) - 0:07:28 - train - INFO - [DocStream] step=67 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=2-3]
2025-11-14 16:21:17 (IST) - 0:07:34 - train - INFO - [TTT] Step 67: grad_norm=9.756e-08, param_norm=1.2233, delta_norm=4.719e-03, relative_change=0.3858% (6 params)
2025-11-14 16:21:17 (IST) - 0:07:34 - train - INFO - step: 000067 - done (%): 3.4 - loss: 4.650 - lr: 7.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5101.7 - avg_words_per_second: 5136.0 - ETA: >2025-11-14 19:52:59
2025-11-14 16:21:17 (IST) - 0:07:34 - train - INFO - [DocStream] step=68 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=4-5]
2025-11-14 16:21:23 (IST) - 0:07:41 - train - INFO - [TTT] Step 68: grad_norm=6.135e-08, param_norm=1.2234, delta_norm=4.045e-03, relative_change=0.3306% (6 params)
2025-11-14 16:21:23 (IST) - 0:07:41 - train - INFO - step: 000068 - done (%): 3.4 - loss: 3.138 - lr: 7.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.8 - avg_words_per_second: 5135.7 - ETA: >2025-11-14 19:53:00
2025-11-14 16:21:24 (IST) - 0:07:41 - train - INFO - [DocStream] step=69 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=6-7]
2025-11-14 16:21:30 (IST) - 0:07:47 - train - INFO - [TTT] Step 69: grad_norm=6.821e-08, param_norm=1.2235, delta_norm=3.650e-03, relative_change=0.2983% (6 params)
2025-11-14 16:21:30 (IST) - 0:07:47 - train - INFO - step: 000069 - done (%): 3.5 - loss: 2.804 - lr: 7.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.6 - avg_words_per_second: 5135.4 - ETA: >2025-11-14 19:53:01
2025-11-14 16:21:30 (IST) - 0:07:47 - train - INFO - [DocStream] step=70 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=8-9]
2025-11-14 16:21:37 (IST) - 0:07:54 - train - INFO - [TTT] Step 70: grad_norm=6.796e-08, param_norm=1.2236, delta_norm=3.313e-03, relative_change=0.2707% (6 params)
2025-11-14 16:21:37 (IST) - 0:07:54 - train - INFO - step: 000070 - done (%): 3.5 - loss: 2.880 - lr: 8.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.9 - avg_words_per_second: 5135.2 - ETA: >2025-11-14 19:53:01
2025-11-14 16:21:37 (IST) - 0:07:54 - train - INFO - [DocStream] step=71 microbatch=0 samples=2 unique_docs=1 runs=4184.wav[segments=10-11]
2025-11-14 16:21:43 (IST) - 0:08:00 - train - INFO - [TTT] Step 71: grad_norm=7.550e-08, param_norm=1.2236, delta_norm=3.147e-03, relative_change=0.2572% (6 params)
2025-11-14 16:21:43 (IST) - 0:08:00 - train - INFO - step: 000071 - done (%): 3.5 - loss: 2.195 - lr: 8.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.9 - avg_words_per_second: 5134.9 - ETA: >2025-11-14 19:53:02
2025-11-14 16:21:44 (IST) - 0:08:01 - train - INFO - [DocStream] step=72 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=0-1]
2025-11-14 16:21:44 (IST) - 0:08:01 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4184.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4234.wav
2025-11-14 16:21:44 (IST) - 0:08:01 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:21:44 (IST) - 0:08:01 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:21:44 (IST) - 0:08:01 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:21:50 (IST) - 0:08:07 - train - INFO - [TTT] Step 72: grad_norm=1.085e-07, param_norm=1.2237, delta_norm=3.088e-03, relative_change=0.2523% (6 params)
2025-11-14 16:21:50 (IST) - 0:08:07 - train - INFO - step: 000072 - done (%): 3.6 - loss: 4.725 - lr: 8.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.1 - avg_words_per_second: 5134.7 - ETA: >2025-11-14 19:53:02
2025-11-14 16:21:50 (IST) - 0:08:07 - train - INFO - [DocStream] step=73 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=2-3]
2025-11-14 16:21:56 (IST) - 0:08:14 - train - INFO - [TTT] Step 73: grad_norm=8.160e-08, param_norm=1.2237, delta_norm=3.189e-03, relative_change=0.2606% (6 params)
2025-11-14 16:21:56 (IST) - 0:08:14 - train - INFO - step: 000073 - done (%): 3.6 - loss: 5.181 - lr: 8.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.8 - avg_words_per_second: 5134.4 - ETA: >2025-11-14 19:53:03
2025-11-14 16:21:57 (IST) - 0:08:14 - train - INFO - [DocStream] step=74 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=4-5]
2025-11-14 16:22:03 (IST) - 0:08:20 - train - INFO - [TTT] Step 74: grad_norm=6.619e-08, param_norm=1.2237, delta_norm=3.336e-03, relative_change=0.2726% (6 params)
2025-11-14 16:22:03 (IST) - 0:08:20 - train - INFO - step: 000074 - done (%): 3.7 - loss: 3.807 - lr: 8.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5118.0 - avg_words_per_second: 5134.2 - ETA: >2025-11-14 19:53:04
2025-11-14 16:22:03 (IST) - 0:08:20 - train - INFO - [DocStream] step=75 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=6-7]
2025-11-14 16:22:10 (IST) - 0:08:27 - train - INFO - [TTT] Step 75: grad_norm=5.748e-08, param_norm=1.2237, delta_norm=3.434e-03, relative_change=0.2806% (6 params)
2025-11-14 16:22:10 (IST) - 0:08:27 - train - INFO - step: 000075 - done (%): 3.8 - loss: 2.451 - lr: 8.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.6 - avg_words_per_second: 5134.0 - ETA: >2025-11-14 19:53:04
2025-11-14 16:22:10 (IST) - 0:08:27 - train - INFO - [DocStream] step=76 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=8-9]
2025-11-14 16:22:16 (IST) - 0:08:33 - train - INFO - [TTT] Step 76: grad_norm=6.765e-08, param_norm=1.2237, delta_norm=3.632e-03, relative_change=0.2968% (6 params)
2025-11-14 16:22:16 (IST) - 0:08:33 - train - INFO - step: 000076 - done (%): 3.8 - loss: 2.976 - lr: 8.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5121.2 - avg_words_per_second: 5133.8 - ETA: >2025-11-14 19:53:05
2025-11-14 16:22:17 (IST) - 0:08:34 - train - INFO - [DocStream] step=77 microbatch=0 samples=2 unique_docs=1 runs=4234.wav[segments=10-11]
2025-11-14 16:22:23 (IST) - 0:08:40 - train - INFO - [TTT] Step 77: grad_norm=5.737e-08, param_norm=1.2237, delta_norm=3.735e-03, relative_change=0.3052% (6 params)
2025-11-14 16:22:23 (IST) - 0:08:40 - train - INFO - step: 000077 - done (%): 3.9 - loss: 2.770 - lr: 8.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5118.2 - avg_words_per_second: 5133.6 - ETA: >2025-11-14 19:53:05
2025-11-14 16:22:23 (IST) - 0:08:40 - train - INFO - [DocStream] step=78 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=0-1]
2025-11-14 16:22:23 (IST) - 0:08:40 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4234.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4245.wav
2025-11-14 16:22:23 (IST) - 0:08:40 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:22:23 (IST) - 0:08:40 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:22:23 (IST) - 0:08:40 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:22:29 (IST) - 0:08:47 - train - INFO - [TTT] Step 78: grad_norm=8.337e-08, param_norm=1.2237, delta_norm=3.576e-03, relative_change=0.2922% (6 params)
2025-11-14 16:22:29 (IST) - 0:08:47 - train - INFO - step: 000078 - done (%): 3.9 - loss: 5.300 - lr: 8.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5115.0 - avg_words_per_second: 5133.4 - ETA: >2025-11-14 19:53:06
2025-11-14 16:22:30 (IST) - 0:08:47 - train - INFO - [DocStream] step=79 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=2-3]
2025-11-14 16:22:36 (IST) - 0:08:53 - train - INFO - [TTT] Step 79: grad_norm=7.923e-08, param_norm=1.2237, delta_norm=3.609e-03, relative_change=0.2949% (6 params)
2025-11-14 16:22:36 (IST) - 0:08:53 - train - INFO - step: 000079 - done (%): 4.0 - loss: 5.473 - lr: 9.0e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.1 - avg_words_per_second: 5133.2 - ETA: >2025-11-14 19:53:06
2025-11-14 16:22:36 (IST) - 0:08:53 - train - INFO - [DocStream] step=80 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=4-5]
2025-11-14 16:22:43 (IST) - 0:09:00 - train - INFO - [TTT] Step 80: grad_norm=5.792e-08, param_norm=1.2237, delta_norm=3.604e-03, relative_change=0.2945% (6 params)
2025-11-14 16:22:43 (IST) - 0:09:00 - train - INFO - step: 000080 - done (%): 4.0 - loss: 4.312 - lr: 9.1e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.2 - avg_words_per_second: 5133.0 - ETA: >2025-11-14 19:53:07
2025-11-14 16:22:43 (IST) - 0:09:00 - train - INFO - [DocStream] step=81 microbatch=0 samples=2 unique_docs=1 runs=4245.wav[segments=6-7]
2025-11-14 16:22:49 (IST) - 0:09:06 - train - INFO - [TTT] Step 81: grad_norm=6.266e-08, param_norm=1.2237, delta_norm=3.732e-03, relative_change=0.3050% (6 params)
2025-11-14 16:22:49 (IST) - 0:09:06 - train - INFO - step: 000081 - done (%): 4.0 - loss: 3.087 - lr: 9.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5102.4 - avg_words_per_second: 5132.6 - ETA: >2025-11-14 19:53:08
2025-11-14 16:22:50 (IST) - 0:09:07 - train - INFO - [DocStream] step=82 microbatch=0 samples=2 unique_docs=2 runs=4245.wav[segment=8], 4247.wav[segment=0]
2025-11-14 16:22:50 (IST) - 0:09:07 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4245.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4247.wav
2025-11-14 16:22:50 (IST) - 0:09:07 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:22:50 (IST) - 0:09:07 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:22:50 (IST) - 0:09:07 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:22:56 (IST) - 0:09:13 - train - INFO - [TTT] Step 82: grad_norm=5.469e-08, param_norm=1.2237, delta_norm=3.640e-03, relative_change=0.2975% (6 params)
2025-11-14 16:22:56 (IST) - 0:09:13 - train - INFO - step: 000082 - done (%): 4.1 - loss: 4.170 - lr: 9.2e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5150.0 - avg_words_per_second: 5132.8 - ETA: >2025-11-14 19:53:07
2025-11-14 16:22:56 (IST) - 0:09:13 - train - INFO - [DocStream] step=83 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=1-2]
2025-11-14 16:23:02 (IST) - 0:09:20 - train - INFO - [TTT] Step 83: grad_norm=7.804e-08, param_norm=1.2237, delta_norm=3.634e-03, relative_change=0.2970% (6 params)
2025-11-14 16:23:02 (IST) - 0:09:20 - train - INFO - step: 000083 - done (%): 4.2 - loss: 4.700 - lr: 9.3e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5114.8 - avg_words_per_second: 5132.6 - ETA: >2025-11-14 19:53:08
2025-11-14 16:23:03 (IST) - 0:09:20 - train - INFO - [DocStream] step=84 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=3-4]
2025-11-14 16:23:09 (IST) - 0:09:26 - train - INFO - [TTT] Step 84: grad_norm=6.470e-08, param_norm=1.2236, delta_norm=3.758e-03, relative_change=0.3071% (6 params)
2025-11-14 16:23:09 (IST) - 0:09:26 - train - INFO - step: 000084 - done (%): 4.2 - loss: 3.917 - lr: 9.4e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.3 - avg_words_per_second: 5132.4 - ETA: >2025-11-14 19:53:08
2025-11-14 16:23:09 (IST) - 0:09:26 - train - INFO - [DocStream] step=85 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=5-6]
2025-11-14 16:23:16 (IST) - 0:09:33 - train - INFO - [TTT] Step 85: grad_norm=4.571e-08, param_norm=1.2236, delta_norm=3.618e-03, relative_change=0.2956% (6 params)
2025-11-14 16:23:16 (IST) - 0:09:33 - train - INFO - step: 000085 - done (%): 4.2 - loss: 2.116 - lr: 9.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.0 - avg_words_per_second: 5132.2 - ETA: >2025-11-14 19:53:09
2025-11-14 16:23:16 (IST) - 0:09:33 - train - INFO - [DocStream] step=86 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=7-8]
2025-11-14 16:23:22 (IST) - 0:09:39 - train - INFO - [TTT] Step 86: grad_norm=4.441e-08, param_norm=1.2236, delta_norm=3.456e-03, relative_change=0.2824% (6 params)
2025-11-14 16:23:22 (IST) - 0:09:39 - train - INFO - step: 000086 - done (%): 4.3 - loss: 2.578 - lr: 9.5e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.1 - avg_words_per_second: 5132.0 - ETA: >2025-11-14 19:53:09
2025-11-14 16:23:23 (IST) - 0:09:40 - train - INFO - [DocStream] step=87 microbatch=0 samples=2 unique_docs=1 runs=4247.wav[segments=9-10]
2025-11-14 16:23:29 (IST) - 0:09:46 - train - INFO - [TTT] Step 87: grad_norm=5.457e-08, param_norm=1.2235, delta_norm=3.403e-03, relative_change=0.2781% (6 params)
2025-11-14 16:23:29 (IST) - 0:09:46 - train - INFO - step: 000087 - done (%): 4.3 - loss: 2.649 - lr: 9.6e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5102.0 - avg_words_per_second: 5131.7 - ETA: >2025-11-14 19:53:10
2025-11-14 16:23:29 (IST) - 0:09:46 - train - INFO - [DocStream] step=88 microbatch=0 samples=2 unique_docs=2 runs=4247.wav[segment=11], 4248.wav[segment=0]
2025-11-14 16:23:29 (IST) - 0:09:46 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4247.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4248.wav
2025-11-14 16:23:29 (IST) - 0:09:46 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:23:29 (IST) - 0:09:46 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:23:29 (IST) - 0:09:46 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:23:35 (IST) - 0:09:53 - train - INFO - [TTT] Step 88: grad_norm=4.591e-08, param_norm=1.2235, delta_norm=3.149e-03, relative_change=0.2574% (6 params)
2025-11-14 16:23:35 (IST) - 0:09:53 - train - INFO - step: 000088 - done (%): 4.4 - loss: 4.109 - lr: 9.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.0 - avg_words_per_second: 5131.5 - ETA: >2025-11-14 19:53:11
2025-11-14 16:23:36 (IST) - 0:09:53 - train - INFO - [DocStream] step=89 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=1-2]
2025-11-14 16:23:42 (IST) - 0:09:59 - train - INFO - [TTT] Step 89: grad_norm=1.292e-07, param_norm=1.2235, delta_norm=3.122e-03, relative_change=0.2551% (6 params)
2025-11-14 16:23:42 (IST) - 0:09:59 - train - INFO - step: 000089 - done (%): 4.5 - loss: 4.855 - lr: 9.7e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5112.9 - avg_words_per_second: 5131.3 - ETA: >2025-11-14 19:53:11
2025-11-14 16:23:42 (IST) - 0:09:59 - train - INFO - [DocStream] step=90 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=3-4]
2025-11-14 16:23:49 (IST) - 0:10:06 - train - INFO - [TTT] Step 90: grad_norm=1.181e-07, param_norm=1.2234, delta_norm=3.548e-03, relative_change=0.2900% (6 params)
2025-11-14 16:23:49 (IST) - 0:10:06 - train - INFO - step: 000090 - done (%): 4.5 - loss: 4.131 - lr: 9.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5105.4 - avg_words_per_second: 5131.0 - ETA: >2025-11-14 19:53:12
2025-11-14 16:23:49 (IST) - 0:10:06 - train - INFO - [DocStream] step=91 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=5-6]
2025-11-14 16:23:55 (IST) - 0:10:12 - train - INFO - [TTT] Step 91: grad_norm=4.977e-08, param_norm=1.2234, delta_norm=3.197e-03, relative_change=0.2613% (6 params)
2025-11-14 16:23:55 (IST) - 0:10:12 - train - INFO - step: 000091 - done (%): 4.5 - loss: 2.828 - lr: 9.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.1 - avg_words_per_second: 5130.9 - ETA: >2025-11-14 19:53:12
2025-11-14 16:23:56 (IST) - 0:10:13 - train - INFO - [DocStream] step=92 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=7-8]
2025-11-14 16:24:02 (IST) - 0:10:19 - train - INFO - [TTT] Step 92: grad_norm=4.034e-08, param_norm=1.2233, delta_norm=2.849e-03, relative_change=0.2329% (6 params)
2025-11-14 16:24:02 (IST) - 0:10:19 - train - INFO - step: 000092 - done (%): 4.6 - loss: 2.461 - lr: 9.8e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5117.8 - avg_words_per_second: 5130.7 - ETA: >2025-11-14 19:53:13
2025-11-14 16:24:02 (IST) - 0:10:19 - train - INFO - [DocStream] step=93 microbatch=0 samples=2 unique_docs=1 runs=4248.wav[segments=9-10]
2025-11-14 16:24:08 (IST) - 0:10:26 - train - INFO - [TTT] Step 93: grad_norm=4.716e-08, param_norm=1.2233, delta_norm=2.602e-03, relative_change=0.2127% (6 params)
2025-11-14 16:24:08 (IST) - 0:10:26 - train - INFO - step: 000093 - done (%): 4.7 - loss: 2.780 - lr: 9.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5101.9 - avg_words_per_second: 5130.4 - ETA: >2025-11-14 19:53:13
2025-11-14 16:24:09 (IST) - 0:10:26 - train - INFO - [DocStream] step=94 microbatch=0 samples=2 unique_docs=2 runs=4248.wav[segment=11], 4289.wav[segment=0]
2025-11-14 16:24:09 (IST) - 0:10:26 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4248.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4289.wav
2025-11-14 16:24:09 (IST) - 0:10:26 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:24:09 (IST) - 0:10:26 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:24:09 (IST) - 0:10:26 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:24:15 (IST) - 0:10:32 - train - INFO - [TTT] Step 94: grad_norm=1.908e-07, param_norm=1.2232, delta_norm=3.762e-03, relative_change=0.3075% (6 params)
2025-11-14 16:24:15 (IST) - 0:10:32 - train - INFO - step: 000094 - done (%): 4.7 - loss: 3.212 - lr: 9.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5098.3 - avg_words_per_second: 5130.1 - ETA: >2025-11-14 19:53:14
2025-11-14 16:24:15 (IST) - 0:10:33 - train - INFO - [DocStream] step=95 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=1-2]
2025-11-14 16:24:22 (IST) - 0:10:39 - train - INFO - [TTT] Step 95: grad_norm=7.175e-08, param_norm=1.2231, delta_norm=4.067e-03, relative_change=0.3325% (6 params)
2025-11-14 16:24:22 (IST) - 0:10:39 - train - INFO - step: 000095 - done (%): 4.8 - loss: 2.368 - lr: 9.9e-04 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5105.3 - avg_words_per_second: 5129.8 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:22 (IST) - 0:10:39 - train - INFO - [DocStream] step=96 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=3-4]
2025-11-14 16:24:28 (IST) - 0:10:45 - train - INFO - [TTT] Step 96: grad_norm=3.141e-08, param_norm=1.2231, delta_norm=3.312e-03, relative_change=0.2708% (6 params)
2025-11-14 16:24:28 (IST) - 0:10:45 - train - INFO - step: 000096 - done (%): 4.8 - loss: 1.117 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5125.2 - avg_words_per_second: 5129.8 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:29 (IST) - 0:10:46 - train - INFO - [DocStream] step=97 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=5-6]
2025-11-14 16:24:35 (IST) - 0:10:52 - train - INFO - [TTT] Step 97: grad_norm=3.514e-08, param_norm=1.2230, delta_norm=2.771e-03, relative_change=0.2265% (6 params)
2025-11-14 16:24:35 (IST) - 0:10:52 - train - INFO - step: 000097 - done (%): 4.8 - loss: 0.906 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5133.8 - avg_words_per_second: 5129.8 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:35 (IST) - 0:10:52 - train - INFO - [DocStream] step=98 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=7-8]
2025-11-14 16:24:41 (IST) - 0:10:59 - train - INFO - [TTT] Step 98: grad_norm=2.969e-08, param_norm=1.2230, delta_norm=2.444e-03, relative_change=0.1998% (6 params)
2025-11-14 16:24:41 (IST) - 0:10:59 - train - INFO - step: 000098 - done (%): 4.9 - loss: 1.402 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5136.8 - avg_words_per_second: 5129.9 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:42 (IST) - 0:10:59 - train - INFO - [DocStream] step=99 microbatch=0 samples=2 unique_docs=1 runs=4289.wav[segments=9-10]
2025-11-14 16:24:48 (IST) - 0:11:05 - train - INFO - [TTT] Step 99: grad_norm=3.814e-08, param_norm=1.2229, delta_norm=2.180e-03, relative_change=0.1782% (6 params)
2025-11-14 16:24:48 (IST) - 0:11:05 - train - INFO - step: 000099 - done (%): 5.0 - loss: 1.453 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5120.2 - avg_words_per_second: 5129.8 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:48 (IST) - 0:11:05 - train - INFO - [DocStream] step=100 microbatch=0 samples=2 unique_docs=2 runs=4289.wav[segment=11], 4290.wav[segment=0]
2025-11-14 16:24:48 (IST) - 0:11:05 - train - INFO - [TTT RESET] Document switch detected: /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4289.wav -> /sise/eliyanac-group/ron_al/talkbank_callhome_english/wav/4290.wav
2025-11-14 16:24:48 (IST) - 0:11:05 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 71.500000 -> 71.500000
2025-11-14 16:24:48 (IST) - 0:11:05 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 73.000000 -> 73.000000
2025-11-14 16:24:48 (IST) - 0:11:05 - moshi.modules.ttt_module - INFO - [TTT RESET] Layer reset: w_down norm 74.000000 -> 74.000000
2025-11-14 16:24:55 (IST) - 0:11:12 - train - INFO - [TTT] Step 100: grad_norm=4.387e-08, param_norm=1.2228, delta_norm=1.783e-03, relative_change=0.1458% (6 params)
2025-11-14 16:24:55 (IST) - 0:11:12 - train - INFO - step: 000100 - done (%): 5.0 - loss: 3.247 - lr: 1.0e-03 - peak_alloc_mem (GB): 37.2 - alloc_mem (GB): 18.6 - words_per_second: 5116.6 - avg_words_per_second: 5129.6 - ETA: >2025-11-14 19:53:15
2025-11-14 16:24:55 (IST) - 0:11:12 - checkpointing - INFO - Dumping checkpoint in /sise/eliyanac-group/ron_al/ttt_training_run2/checkpoints/checkpoint_000100/consolidated using tmp name: tmp.consolidated
2025-11-14 16:24:55 (IST) - 0:11:12 - utils - INFO - Closing: eval_logger
2025-11-14 16:24:56 (IST) - 0:11:13 - utils - INFO - Closed: eval_logger
2025-11-14 16:24:56 (IST) - 0:11:13 - utils - INFO - Closing: metrics_logger
2025-11-14 16:24:56 (IST) - 0:11:13 - utils - INFO - Closed: metrics_logger
==================================================
Job finished at: Fri 14 Nov 2025 16:24:59 IST
==================================================
