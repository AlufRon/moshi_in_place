[rank0]:[W1114 16:13:47.460550122 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
wandb: Currently logged in as: alufr (alufr-ben-gurion-university-of-the-negev) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_161347-f4n0lsi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run2
wandb: â­ï¸ View project at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: ğŸš€ View run at https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/f4n0lsi2
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi/moshi/moshi/models/loaders.py:204: UserWarning: Repository kyutai/moshiko-pytorch-bf16 contains no config.json. Assuming this is a Moshi 7B. Support for such repository might be removed in the future.
  warnings.warn(
2025-11-14 16:13:51 (IST) - 0:00:08 - finetune.wrapped_model - WARNING - Buffer transformer.layers.10.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:13:52 (IST) - 0:00:09 - finetune.wrapped_model - WARNING - Buffer transformer.layers.20.gating.ttt_clip_event_counter still meta - initializing as zeros
2025-11-14 16:13:53 (IST) - 0:00:10 - finetune.wrapped_model - WARNING - Buffer transformer.layers.30.gating.ttt_clip_event_counter still meta - initializing as zeros
wandb: uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:           train/allocated_mem â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 train/avg_wps â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:          train/eta_in_seconds â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                    train/loss â–…â–‡â–ƒâ–„â–„â–ƒâ–…â–ƒâ–†â–‚â–„â–ƒâ–ƒâ–‚â–‡â–…â–ƒâ–ƒâ–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–„â–„â–ƒâ–…â–„â–ˆâ–ˆâ–†â–ƒâ–ƒâ–†â–†â–
wandb:                      train/lr â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      train/peak_allocated_mem â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            train/percent_done â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        train/prob_real_tokens â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆ
wandb:          train/ttt/delta_norm â–„â–ƒâ–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–„â–„â–ƒâ–„â–‡â–‡â–ˆâ–‡â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–‚
wandb:           train/ttt/grad_norm â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train/ttt/param_count â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/ttt/param_norm â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–…
wandb: train/ttt/relative_change_pct â–…â–ƒâ–ƒâ–â–â–â–‚â–‚â–â–â–â–â–â–â–â–…â–ƒâ–ƒâ–„â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–…â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–‚
wandb:                     train/wps â–â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb: 
wandb: Run summary:
wandb:           train/allocated_mem 18.6341
wandb:                 train/avg_wps 5129.6376
wandb:          train/eta_in_seconds 12500.8831
wandb:                    train/loss 3.24681
wandb:                      train/lr 0.001
wandb:      train/peak_allocated_mem 37.20884
wandb:            train/percent_done 5
wandb:        train/prob_real_tokens 0.99959
wandb:          train/ttt/delta_norm 0.00178
wandb:           train/ttt/grad_norm 0.0
wandb:         train/ttt/param_count 6
wandb:          train/ttt/param_norm 1.22281
wandb: train/ttt/relative_change_pct 0.14578
wandb:                     train/wps 5116.59301
wandb: 
wandb: ğŸš€ View run run2 at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place/runs/f4n0lsi2
wandb: â­ï¸ View project at: https://wandb.ai/alufr-ben-gurion-university-of-the-negev/moshi_in_place
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /sise/eliyanac-group/ron_al/ttt_training_run2/wandb/run-20251114_161347-f4n0lsi2/logs
Traceback (most recent call last):
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 533, in <module>
    fire.Fire(train)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 118, in train
    _train(args, exit_stack)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 523, in _train
    checkpointer.save_checkpoint(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/finetune/checkpointing.py", line 213, in save_checkpoint
    assert not self.dst_dir.exists(), f"dst exists {self.dst_dir}"
AssertionError: dst exists /sise/eliyanac-group/ron_al/ttt_training_run2/checkpoints/checkpoint_000100/consolidated
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 533, in <module>
[rank0]:     fire.Fire(train)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 135, in Fire
[rank0]:     component_trace = _Fire(component, args, parsed_flag_args, context, name)
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 468, in _Fire
[rank0]:     component, remaining_args = _CallAndUpdateTrace(
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/fire/core.py", line 684, in _CallAndUpdateTrace
[rank0]:     component = fn(*varargs, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 118, in train
[rank0]:     _train(args, exit_stack)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/train.py", line 523, in _train
[rank0]:     checkpointer.save_checkpoint(
[rank0]:   File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/alufr/moshi_in_place_ttt/moshi_in_place/moshi-finetune/finetune/checkpointing.py", line 213, in save_checkpoint
[rank0]:     assert not self.dst_dir.exists(), f"dst exists {self.dst_dir}"
[rank0]: AssertionError: dst exists /sise/eliyanac-group/ron_al/ttt_training_run2/checkpoints/checkpoint_000100/consolidated
[rank0]:[W1114 16:24:57.189533741 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
E1114 16:24:59.205000 3068486 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 3068496) of binary: /home/alufr/.conda/envs/moshi_ttt_fixed/bin/python3.10
Traceback (most recent call last):
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/run.py", line 918, in main
    run(args)
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/alufr/.conda/envs/moshi_ttt_fixed/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-14_16:24:59
  host      : cs-6000-03.auth.ad.bgu.ac.il
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3068496)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
